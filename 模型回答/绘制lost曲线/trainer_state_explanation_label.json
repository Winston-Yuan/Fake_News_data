{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.998704476752555,
  "eval_steps": 500,
  "global_step": 2604,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 2.255898952484131,
      "learning_rate": 4.999954515178957e-05,
      "loss": 1.8389,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.549192190170288,
      "learning_rate": 4.999818062370922e-05,
      "loss": 1.6968,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2138044834136963,
      "learning_rate": 4.99959064654112e-05,
      "loss": 1.5294,
      "step": 15
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.519752562046051,
      "learning_rate": 4.999272275964727e-05,
      "loss": 1.4599,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3202764391899109,
      "learning_rate": 4.998862962226565e-05,
      "loss": 1.4242,
      "step": 25
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.33835262060165405,
      "learning_rate": 4.998362720220684e-05,
      "loss": 1.3947,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3473326563835144,
      "learning_rate": 4.997771568149818e-05,
      "loss": 1.3607,
      "step": 35
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.38969600200653076,
      "learning_rate": 4.997089527524725e-05,
      "loss": 1.3151,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.37108081579208374,
      "learning_rate": 4.996316623163401e-05,
      "loss": 1.3189,
      "step": 45
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3504711985588074,
      "learning_rate": 4.9954528831901795e-05,
      "loss": 1.2595,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.36474260687828064,
      "learning_rate": 4.9944983390347054e-05,
      "loss": 1.2368,
      "step": 55
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.36221492290496826,
      "learning_rate": 4.993453025430797e-05,
      "loss": 1.216,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.34679320454597473,
      "learning_rate": 4.992316980415175e-05,
      "loss": 1.1871,
      "step": 65
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3261539936065674,
      "learning_rate": 4.9910902453260824e-05,
      "loss": 1.1753,
      "step": 70
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3284878134727478,
      "learning_rate": 4.989772864801782e-05,
      "loss": 1.1437,
      "step": 75
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.31931862235069275,
      "learning_rate": 4.988364886778925e-05,
      "loss": 1.1233,
      "step": 80
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.31312552094459534,
      "learning_rate": 4.986866362490815e-05,
      "loss": 1.1361,
      "step": 85
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3555225729942322,
      "learning_rate": 4.98527734646554e-05,
      "loss": 1.0889,
      "step": 90
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3324052691459656,
      "learning_rate": 4.983597896523987e-05,
      "loss": 1.0919,
      "step": 95
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3506873846054077,
      "learning_rate": 4.981828073777741e-05,
      "loss": 1.1161,
      "step": 100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3725971579551697,
      "learning_rate": 4.979967942626858e-05,
      "loss": 1.1012,
      "step": 105
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35949355363845825,
      "learning_rate": 4.9780175707575234e-05,
      "loss": 1.0874,
      "step": 110
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35605019330978394,
      "learning_rate": 4.9759770291395904e-05,
      "loss": 1.1013,
      "step": 115
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3480083644390106,
      "learning_rate": 4.9738463920239955e-05,
      "loss": 1.058,
      "step": 120
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.36955738067626953,
      "learning_rate": 4.9716257369400554e-05,
      "loss": 1.0607,
      "step": 125
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3910329341888428,
      "learning_rate": 4.969315144692651e-05,
      "loss": 1.0188,
      "step": 130
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3724238872528076,
      "learning_rate": 4.966914699359282e-05,
      "loss": 1.0456,
      "step": 135
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3865460157394409,
      "learning_rate": 4.964424488287009e-05,
      "loss": 1.06,
      "step": 140
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3997184932231903,
      "learning_rate": 4.961844602089277e-05,
      "loss": 1.0085,
      "step": 145
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4052731692790985,
      "learning_rate": 4.959175134642614e-05,
      "loss": 0.9848,
      "step": 150
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.44011786580085754,
      "learning_rate": 4.956416183083221e-05,
      "loss": 1.0019,
      "step": 155
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.41343954205513,
      "learning_rate": 4.9535678478034307e-05,
      "loss": 1.0241,
      "step": 160
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.42896655201911926,
      "learning_rate": 4.9506302324480605e-05,
      "loss": 1.0075,
      "step": 165
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.46584653854370117,
      "learning_rate": 4.947603443910637e-05,
      "loss": 0.9645,
      "step": 170
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47273024916648865,
      "learning_rate": 4.944487592329509e-05,
      "loss": 1.0146,
      "step": 175
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.43934354186058044,
      "learning_rate": 4.941282791083836e-05,
      "loss": 0.9739,
      "step": 180
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4327322244644165,
      "learning_rate": 4.937989156789469e-05,
      "loss": 0.985,
      "step": 185
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4952073395252228,
      "learning_rate": 4.9346068092946996e-05,
      "loss": 0.9478,
      "step": 190
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4979359209537506,
      "learning_rate": 4.931135871675905e-05,
      "loss": 0.9607,
      "step": 195
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5112814903259277,
      "learning_rate": 4.927576470233065e-05,
      "loss": 0.9775,
      "step": 200
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4930744767189026,
      "learning_rate": 4.923928734485172e-05,
      "loss": 0.9709,
      "step": 205
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.48712414503097534,
      "learning_rate": 4.920192797165511e-05,
      "loss": 0.9522,
      "step": 210
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4869835674762726,
      "learning_rate": 4.916368794216834e-05,
      "loss": 0.9435,
      "step": 215
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.46957704424858093,
      "learning_rate": 4.9124568647864134e-05,
      "loss": 0.9791,
      "step": 220
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5547579526901245,
      "learning_rate": 4.908457151220976e-05,
      "loss": 0.941,
      "step": 225
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5007030367851257,
      "learning_rate": 4.904369799061529e-05,
      "loss": 0.9383,
      "step": 230
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5357146263122559,
      "learning_rate": 4.900194957038056e-05,
      "loss": 0.9433,
      "step": 235
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5110456347465515,
      "learning_rate": 4.89593277706411e-05,
      "loss": 0.9351,
      "step": 240
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.572881817817688,
      "learning_rate": 4.891583414231287e-05,
      "loss": 0.921,
      "step": 245
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5645506978034973,
      "learning_rate": 4.887147026803578e-05,
      "loss": 0.9226,
      "step": 250
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5713436007499695,
      "learning_rate": 4.8826237762116144e-05,
      "loss": 0.9241,
      "step": 255
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6297590136528015,
      "learning_rate": 4.8780138270467915e-05,
      "loss": 0.9135,
      "step": 260
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5709720253944397,
      "learning_rate": 4.873317347055279e-05,
      "loss": 0.9057,
      "step": 265
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5786677598953247,
      "learning_rate": 4.868534507131919e-05,
      "loss": 0.911,
      "step": 270
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5455329418182373,
      "learning_rate": 4.8636654813140044e-05,
      "loss": 0.9229,
      "step": 275
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6159005761146545,
      "learning_rate": 4.858710446774951e-05,
      "loss": 0.9066,
      "step": 280
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5864865779876709,
      "learning_rate": 4.8536695838178456e-05,
      "loss": 0.9321,
      "step": 285
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5527685284614563,
      "learning_rate": 4.8485430758688885e-05,
      "loss": 0.9175,
      "step": 290
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6162171959877014,
      "learning_rate": 4.843331109470716e-05,
      "loss": 0.8627,
      "step": 295
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6547571420669556,
      "learning_rate": 4.8380338742756157e-05,
      "loss": 0.8948,
      "step": 300
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6472800970077515,
      "learning_rate": 4.832651563038624e-05,
      "loss": 0.8841,
      "step": 305
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6430137157440186,
      "learning_rate": 4.827184371610511e-05,
      "loss": 0.8707,
      "step": 310
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6933679580688477,
      "learning_rate": 4.821632498930656e-05,
      "loss": 0.905,
      "step": 315
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6586598753929138,
      "learning_rate": 4.8159961470198065e-05,
      "loss": 0.9079,
      "step": 320
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.645497739315033,
      "learning_rate": 4.81027552097273e-05,
      "loss": 0.875,
      "step": 325
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6437577605247498,
      "learning_rate": 4.804470828950748e-05,
      "loss": 0.8712,
      "step": 330
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.63763427734375,
      "learning_rate": 4.798582282174161e-05,
      "loss": 0.8649,
      "step": 335
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6413364410400391,
      "learning_rate": 4.7926100949145685e-05,
      "loss": 0.89,
      "step": 340
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7247904539108276,
      "learning_rate": 4.786554484487064e-05,
      "loss": 0.8793,
      "step": 345
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6762043237686157,
      "learning_rate": 4.780415671242334e-05,
      "loss": 0.8443,
      "step": 350
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6188791394233704,
      "learning_rate": 4.7741938785586347e-05,
      "loss": 0.859,
      "step": 355
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6793403029441833,
      "learning_rate": 4.767889332833667e-05,
      "loss": 0.8758,
      "step": 360
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6808143258094788,
      "learning_rate": 4.7615022634763405e-05,
      "loss": 0.8956,
      "step": 365
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7059723734855652,
      "learning_rate": 4.7550329028984184e-05,
      "loss": 0.8624,
      "step": 370
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6869717240333557,
      "learning_rate": 4.748481486506069e-05,
      "loss": 0.8749,
      "step": 375
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6503798365592957,
      "learning_rate": 4.741848252691292e-05,
      "loss": 0.8497,
      "step": 380
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7285871505737305,
      "learning_rate": 4.735133442823252e-05,
      "loss": 0.8568,
      "step": 385
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7231536507606506,
      "learning_rate": 4.728337301239487e-05,
      "loss": 0.8759,
      "step": 390
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7434039115905762,
      "learning_rate": 4.7214600752370266e-05,
      "loss": 0.827,
      "step": 395
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7379575967788696,
      "learning_rate": 4.714502015063383e-05,
      "loss": 0.8624,
      "step": 400
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.697778046131134,
      "learning_rate": 4.7074633739074555e-05,
      "loss": 0.8772,
      "step": 405
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7539131045341492,
      "learning_rate": 4.70034440789031e-05,
      "loss": 0.8406,
      "step": 410
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7997692823410034,
      "learning_rate": 4.6931453760558636e-05,
      "loss": 0.8442,
      "step": 415
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7453530430793762,
      "learning_rate": 4.685866540361456e-05,
      "loss": 0.854,
      "step": 420
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6864389181137085,
      "learning_rate": 4.678508165668317e-05,
      "loss": 0.8596,
      "step": 425
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7672227025032043,
      "learning_rate": 4.671070519731933e-05,
      "loss": 0.8422,
      "step": 430
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9204631447792053,
      "learning_rate": 4.663553873192299e-05,
      "loss": 0.8308,
      "step": 435
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7608972191810608,
      "learning_rate": 4.655958499564072e-05,
      "loss": 0.8317,
      "step": 440
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7710293531417847,
      "learning_rate": 4.6482846752266224e-05,
      "loss": 0.8539,
      "step": 445
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8014606237411499,
      "learning_rate": 4.6405326794139696e-05,
      "loss": 0.8438,
      "step": 450
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7782769799232483,
      "learning_rate": 4.6327027942046286e-05,
      "loss": 0.8638,
      "step": 455
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8131133317947388,
      "learning_rate": 4.6247953045113415e-05,
      "loss": 0.8436,
      "step": 460
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7798639535903931,
      "learning_rate": 4.6168104980707107e-05,
      "loss": 0.858,
      "step": 465
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7493976950645447,
      "learning_rate": 4.60874866543273e-05,
      "loss": 0.8601,
      "step": 470
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7347465753555298,
      "learning_rate": 4.6006100999502096e-05,
      "loss": 0.8379,
      "step": 475
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7363570332527161,
      "learning_rate": 4.5923950977681084e-05,
      "loss": 0.8665,
      "step": 480
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.795225203037262,
      "learning_rate": 4.5841039578127475e-05,
      "loss": 0.8413,
      "step": 485
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.830696702003479,
      "learning_rate": 4.5757369817809415e-05,
      "loss": 0.871,
      "step": 490
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7177804112434387,
      "learning_rate": 4.567294474129015e-05,
      "loss": 0.8375,
      "step": 495
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7629303336143494,
      "learning_rate": 4.558776742061729e-05,
      "loss": 0.8356,
      "step": 500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7835807800292969,
      "learning_rate": 4.550184095521098e-05,
      "loss": 0.8381,
      "step": 505
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7453900575637817,
      "learning_rate": 4.541516847175115e-05,
      "loss": 0.8226,
      "step": 510
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8432753682136536,
      "learning_rate": 4.532775312406371e-05,
      "loss": 0.8437,
      "step": 515
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7836863994598389,
      "learning_rate": 4.523959809300582e-05,
      "loss": 0.8117,
      "step": 520
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7680152058601379,
      "learning_rate": 4.515070658635013e-05,
      "loss": 0.8508,
      "step": 525
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7675897479057312,
      "learning_rate": 4.506108183866805e-05,
      "loss": 0.8658,
      "step": 530
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8546611070632935,
      "learning_rate": 4.4970727111212085e-05,
      "loss": 0.8384,
      "step": 535
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9129366278648376,
      "learning_rate": 4.487964569179711e-05,
      "loss": 0.8242,
      "step": 540
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8223814368247986,
      "learning_rate": 4.4787840894680774e-05,
      "loss": 0.8191,
      "step": 545
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8568919897079468,
      "learning_rate": 4.46953160604429e-05,
      "loss": 0.8368,
      "step": 550
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9008315205574036,
      "learning_rate": 4.46020745558639e-05,
      "loss": 0.8206,
      "step": 555
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.876909613609314,
      "learning_rate": 4.45081197738023e-05,
      "loss": 0.831,
      "step": 560
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.851571261882782,
      "learning_rate": 4.441345513307125e-05,
      "loss": 0.8206,
      "step": 565
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8679210543632507,
      "learning_rate": 4.431808407831416e-05,
      "loss": 0.7985,
      "step": 570
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8102424740791321,
      "learning_rate": 4.42220100798793e-05,
      "loss": 0.8459,
      "step": 575
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9326410293579102,
      "learning_rate": 4.412523663369358e-05,
      "loss": 0.8405,
      "step": 580
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9335989952087402,
      "learning_rate": 4.40277672611353e-05,
      "loss": 0.8147,
      "step": 585
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8461903929710388,
      "learning_rate": 4.392960550890604e-05,
      "loss": 0.8083,
      "step": 590
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.832429051399231,
      "learning_rate": 4.383075494890159e-05,
      "loss": 0.8063,
      "step": 595
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8765155673027039,
      "learning_rate": 4.373121917808196e-05,
      "loss": 0.8003,
      "step": 600
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8082478046417236,
      "learning_rate": 4.3631001818340545e-05,
      "loss": 0.8362,
      "step": 605
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.854658842086792,
      "learning_rate": 4.353010651637227e-05,
      "loss": 0.8469,
      "step": 610
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8046538233757019,
      "learning_rate": 4.342853694354095e-05,
      "loss": 0.8056,
      "step": 615
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8731979727745056,
      "learning_rate": 4.332629679574566e-05,
      "loss": 0.852,
      "step": 620
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8391088247299194,
      "learning_rate": 4.3223389793286254e-05,
      "loss": 0.8021,
      "step": 625
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8485435843467712,
      "learning_rate": 4.3119819680728e-05,
      "loss": 0.836,
      "step": 630
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8778998255729675,
      "learning_rate": 4.301559022676534e-05,
      "loss": 0.7973,
      "step": 635
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7945543527603149,
      "learning_rate": 4.291070522408471e-05,
      "loss": 0.7992,
      "step": 640
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8900080919265747,
      "learning_rate": 4.280516848922658e-05,
      "loss": 0.8142,
      "step": 645
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.957263708114624,
      "learning_rate": 4.269898386244655e-05,
      "loss": 0.8047,
      "step": 650
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.783953070640564,
      "learning_rate": 4.25921552075756e-05,
      "loss": 0.817,
      "step": 655
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9098623991012573,
      "learning_rate": 4.2484686411879554e-05,
      "loss": 0.8408,
      "step": 660
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9156707525253296,
      "learning_rate": 4.2376581385917547e-05,
      "loss": 0.8022,
      "step": 665
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8299970626831055,
      "learning_rate": 4.2267844063399795e-05,
      "loss": 0.8377,
      "step": 670
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7806053757667542,
      "learning_rate": 4.215847840104442e-05,
      "loss": 0.8128,
      "step": 675
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8413944840431213,
      "learning_rate": 4.2048488378433493e-05,
      "loss": 0.8095,
      "step": 680
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8835294246673584,
      "learning_rate": 4.193787799786819e-05,
      "loss": 0.8388,
      "step": 685
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.863135576248169,
      "learning_rate": 4.182665128422323e-05,
      "loss": 0.8344,
      "step": 690
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9122377634048462,
      "learning_rate": 4.171481228480032e-05,
      "loss": 0.7939,
      "step": 695
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8303295969963074,
      "learning_rate": 4.160236506918098e-05,
      "loss": 0.814,
      "step": 700
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9018602967262268,
      "learning_rate": 4.1489313729078376e-05,
      "loss": 0.8531,
      "step": 705
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8756287097930908,
      "learning_rate": 4.137566237818851e-05,
      "loss": 0.8184,
      "step": 710
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9937898516654968,
      "learning_rate": 4.126141515204044e-05,
      "loss": 0.8251,
      "step": 715
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8870919942855835,
      "learning_rate": 4.114657620784589e-05,
      "loss": 0.8345,
      "step": 720
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9461072683334351,
      "learning_rate": 4.103114972434792e-05,
      "loss": 0.8101,
      "step": 725
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8916562795639038,
      "learning_rate": 4.091513990166889e-05,
      "loss": 0.7834,
      "step": 730
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9880673289299011,
      "learning_rate": 4.07985509611576e-05,
      "loss": 0.8378,
      "step": 735
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8585586547851562,
      "learning_rate": 4.068138714523575e-05,
      "loss": 0.826,
      "step": 740
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8698873519897461,
      "learning_rate": 4.0563652717243486e-05,
      "loss": 0.7993,
      "step": 745
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0449481010437012,
      "learning_rate": 4.0445351961284326e-05,
      "loss": 0.7896,
      "step": 750
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9542876482009888,
      "learning_rate": 4.032648918206923e-05,
      "loss": 0.8057,
      "step": 755
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.940667986869812,
      "learning_rate": 4.020706870476e-05,
      "loss": 0.8039,
      "step": 760
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9064891934394836,
      "learning_rate": 4.008709487481187e-05,
      "loss": 0.787,
      "step": 765
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9319074749946594,
      "learning_rate": 3.9966572057815373e-05,
      "loss": 0.8142,
      "step": 770
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8532634973526001,
      "learning_rate": 3.9845504639337535e-05,
      "loss": 0.805,
      "step": 775
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.013910174369812,
      "learning_rate": 3.9723897024762255e-05,
      "loss": 0.7964,
      "step": 780
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9183000922203064,
      "learning_rate": 3.960175363912997e-05,
      "loss": 0.8548,
      "step": 785
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.9105353951454163,
      "learning_rate": 3.947907892697674e-05,
      "loss": 0.7701,
      "step": 790
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9373896718025208,
      "learning_rate": 3.935587735217242e-05,
      "loss": 0.8184,
      "step": 795
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.887976884841919,
      "learning_rate": 3.923215339775826e-05,
      "loss": 0.7882,
      "step": 800
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.885811984539032,
      "learning_rate": 3.910791156578382e-05,
      "loss": 0.7908,
      "step": 805
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8776372075080872,
      "learning_rate": 3.898315637714308e-05,
      "loss": 0.8265,
      "step": 810
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9930567145347595,
      "learning_rate": 3.885789237141e-05,
      "loss": 0.7717,
      "step": 815
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9830665588378906,
      "learning_rate": 3.8732124106673277e-05,
      "loss": 0.8042,
      "step": 820
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8846858739852905,
      "learning_rate": 3.860585615937051e-05,
      "loss": 0.7838,
      "step": 825
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9608523845672607,
      "learning_rate": 3.8479093124121724e-05,
      "loss": 0.799,
      "step": 830
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9288140535354614,
      "learning_rate": 3.8351839613562065e-05,
      "loss": 0.7961,
      "step": 835
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9277916550636292,
      "learning_rate": 3.822410025817406e-05,
      "loss": 0.8263,
      "step": 840
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8966865539550781,
      "learning_rate": 3.809587970611911e-05,
      "loss": 0.7986,
      "step": 845
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9105107188224792,
      "learning_rate": 3.796718262306827e-05,
      "loss": 0.8099,
      "step": 850
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9374102354049683,
      "learning_rate": 3.78380136920326e-05,
      "loss": 0.7986,
      "step": 855
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.0067838430404663,
      "learning_rate": 3.770837761319267e-05,
      "loss": 0.8182,
      "step": 860
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0118144750595093,
      "learning_rate": 3.757827910372754e-05,
      "loss": 0.8011,
      "step": 865
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9317359924316406,
      "learning_rate": 3.744772289764316e-05,
      "loss": 0.8024,
      "step": 870
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.9020476937294006,
      "learning_rate": 3.731671374560007e-05,
      "loss": 0.8054,
      "step": 875
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.9771714210510254,
      "learning_rate": 3.718525641474052e-05,
      "loss": 0.7887,
      "step": 880
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8556222319602966,
      "learning_rate": 3.705335568851506e-05,
      "loss": 0.7767,
      "step": 885
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.0500915050506592,
      "learning_rate": 3.6921016366508424e-05,
      "loss": 0.8052,
      "step": 890
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.0356186628341675,
      "learning_rate": 3.678824326426492e-05,
      "loss": 0.7953,
      "step": 895
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.947641909122467,
      "learning_rate": 3.6655041213113184e-05,
      "loss": 0.7886,
      "step": 900
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.971455991268158,
      "learning_rate": 3.652141505999039e-05,
      "loss": 0.7705,
      "step": 905
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9900956153869629,
      "learning_rate": 3.638736966726585e-05,
      "loss": 0.8022,
      "step": 910
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9208037257194519,
      "learning_rate": 3.625290991256414e-05,
      "loss": 0.7899,
      "step": 915
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.0093752145767212,
      "learning_rate": 3.611804068858756e-05,
      "loss": 0.7842,
      "step": 920
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.9309099912643433,
      "learning_rate": 3.598276690293811e-05,
      "loss": 0.7667,
      "step": 925
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.9694329500198364,
      "learning_rate": 3.5847093477938956e-05,
      "loss": 0.7607,
      "step": 930
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.969622015953064,
      "learning_rate": 3.571102535045525e-05,
      "loss": 0.8056,
      "step": 935
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.0002729892730713,
      "learning_rate": 3.5574567471714545e-05,
      "loss": 0.7801,
      "step": 940
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.962177574634552,
      "learning_rate": 3.543772480712658e-05,
      "loss": 0.7962,
      "step": 945
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.956193745136261,
      "learning_rate": 3.530050233610266e-05,
      "loss": 0.7826,
      "step": 950
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0076509714126587,
      "learning_rate": 3.516290505187441e-05,
      "loss": 0.807,
      "step": 955
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.0658295154571533,
      "learning_rate": 3.50249379613121e-05,
      "loss": 0.7916,
      "step": 960
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.9200696349143982,
      "learning_rate": 3.488660608474248e-05,
      "loss": 0.757,
      "step": 965
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9697443842887878,
      "learning_rate": 3.4747914455766065e-05,
      "loss": 0.7955,
      "step": 970
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.0303717851638794,
      "learning_rate": 3.4608868121074e-05,
      "loss": 0.808,
      "step": 975
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.098550796508789,
      "learning_rate": 3.44694721402644e-05,
      "loss": 0.793,
      "step": 980
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.0146467685699463,
      "learning_rate": 3.432973158565827e-05,
      "loss": 0.812,
      "step": 985
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.901688814163208,
      "learning_rate": 3.4189651542114884e-05,
      "loss": 0.8018,
      "step": 990
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9434640407562256,
      "learning_rate": 3.4049237106846823e-05,
      "loss": 0.7988,
      "step": 995
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.939490556716919,
      "learning_rate": 3.390849338923446e-05,
      "loss": 0.7696,
      "step": 1000
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.003923773765564,
      "learning_rate": 3.3767425510640026e-05,
      "loss": 0.7998,
      "step": 1005
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9233819842338562,
      "learning_rate": 3.362603860422131e-05,
      "loss": 0.7369,
      "step": 1010
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.9406888484954834,
      "learning_rate": 3.348433781474481e-05,
      "loss": 0.7931,
      "step": 1015
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0814175605773926,
      "learning_rate": 3.3342328298398565e-05,
      "loss": 0.7817,
      "step": 1020
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.9947090148925781,
      "learning_rate": 3.320001522260454e-05,
      "loss": 0.8051,
      "step": 1025
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0625948905944824,
      "learning_rate": 3.305740376583055e-05,
      "loss": 0.7677,
      "step": 1030
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9295792579650879,
      "learning_rate": 3.2914499117401865e-05,
      "loss": 0.7771,
      "step": 1035
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.035067081451416,
      "learning_rate": 3.277130647731238e-05,
      "loss": 0.7937,
      "step": 1040
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.896510124206543,
      "learning_rate": 3.262783105603538e-05,
      "loss": 0.7987,
      "step": 1045
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.9856715798377991,
      "learning_rate": 3.2484078074333954e-05,
      "loss": 0.7773,
      "step": 1050
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.005696415901184,
      "learning_rate": 3.234005276307102e-05,
      "loss": 0.7691,
      "step": 1055
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.9823268055915833,
      "learning_rate": 3.219576036301898e-05,
      "loss": 0.7947,
      "step": 1060
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9994245767593384,
      "learning_rate": 3.205120612466904e-05,
      "loss": 0.7739,
      "step": 1065
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9642031192779541,
      "learning_rate": 3.190639530804011e-05,
      "loss": 0.7728,
      "step": 1070
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0010473728179932,
      "learning_rate": 3.176133318248748e-05,
      "loss": 0.7412,
      "step": 1075
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0694514513015747,
      "learning_rate": 3.161602502651099e-05,
      "loss": 0.7866,
      "step": 1080
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9480212330818176,
      "learning_rate": 3.147047612756302e-05,
      "loss": 0.7828,
      "step": 1085
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9890235662460327,
      "learning_rate": 3.132469178185607e-05,
      "loss": 0.7667,
      "step": 1090
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1557024717330933,
      "learning_rate": 3.117867729417004e-05,
      "loss": 0.7839,
      "step": 1095
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.0137665271759033,
      "learning_rate": 3.1032437977659196e-05,
      "loss": 0.766,
      "step": 1100
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9888337254524231,
      "learning_rate": 3.088597915365886e-05,
      "loss": 0.7863,
      "step": 1105
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9818494319915771,
      "learning_rate": 3.073930615149174e-05,
      "loss": 0.7987,
      "step": 1110
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9939222931861877,
      "learning_rate": 3.0592424308274064e-05,
      "loss": 0.7692,
      "step": 1115
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.9679750204086304,
      "learning_rate": 3.0445338968721287e-05,
      "loss": 0.7577,
      "step": 1120
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9873844981193542,
      "learning_rate": 3.029805548495371e-05,
      "loss": 0.7664,
      "step": 1125
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.0729877948760986,
      "learning_rate": 3.015057921630163e-05,
      "loss": 0.7709,
      "step": 1130
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.022320032119751,
      "learning_rate": 3.0002915529110425e-05,
      "loss": 0.7939,
      "step": 1135
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.147218942642212,
      "learning_rate": 2.9855069796545186e-05,
      "loss": 0.7826,
      "step": 1140
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9662497043609619,
      "learning_rate": 2.9707047398395273e-05,
      "loss": 0.7661,
      "step": 1145
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9361407160758972,
      "learning_rate": 2.9558853720878503e-05,
      "loss": 0.7653,
      "step": 1150
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.0002802610397339,
      "learning_rate": 2.9410494156445216e-05,
      "loss": 0.768,
      "step": 1155
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0514355897903442,
      "learning_rate": 2.926197410358199e-05,
      "loss": 0.7534,
      "step": 1160
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0267056226730347,
      "learning_rate": 2.911329896661525e-05,
      "loss": 0.769,
      "step": 1165
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.9647029638290405,
      "learning_rate": 2.8964474155514588e-05,
      "loss": 0.8024,
      "step": 1170
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.0616185665130615,
      "learning_rate": 2.881550508569594e-05,
      "loss": 0.765,
      "step": 1175
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.9532763361930847,
      "learning_rate": 2.8666397177824473e-05,
      "loss": 0.7793,
      "step": 1180
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.0324608087539673,
      "learning_rate": 2.8517155857617405e-05,
      "loss": 0.7695,
      "step": 1185
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9948067665100098,
      "learning_rate": 2.836778655564653e-05,
      "loss": 0.7743,
      "step": 1190
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0832616090774536,
      "learning_rate": 2.821829470714061e-05,
      "loss": 0.7537,
      "step": 1195
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0509148836135864,
      "learning_rate": 2.8068685751787636e-05,
      "loss": 0.7824,
      "step": 1200
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.036501169204712,
      "learning_rate": 2.791896513353686e-05,
      "loss": 0.7757,
      "step": 1205
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1078503131866455,
      "learning_rate": 2.7769138300400694e-05,
      "loss": 0.7523,
      "step": 1210
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0477718114852905,
      "learning_rate": 2.76192107042565e-05,
      "loss": 0.7399,
      "step": 1215
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0315533876419067,
      "learning_rate": 2.746918780064818e-05,
      "loss": 0.7735,
      "step": 1220
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.9793789982795715,
      "learning_rate": 2.7319075048587666e-05,
      "loss": 0.7558,
      "step": 1225
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.036972999572754,
      "learning_rate": 2.71688779103563e-05,
      "loss": 0.7898,
      "step": 1230
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0573971271514893,
      "learning_rate": 2.701860185130604e-05,
      "loss": 0.769,
      "step": 1235
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0088938474655151,
      "learning_rate": 2.686825233966061e-05,
      "loss": 0.8086,
      "step": 1240
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0030903816223145,
      "learning_rate": 2.671783484631651e-05,
      "loss": 0.7546,
      "step": 1245
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.0789321660995483,
      "learning_rate": 2.656735484464396e-05,
      "loss": 0.78,
      "step": 1250
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.04422926902771,
      "learning_rate": 2.6416817810287713e-05,
      "loss": 0.8036,
      "step": 1255
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.0419529676437378,
      "learning_rate": 2.6266229220967818e-05,
      "loss": 0.7798,
      "step": 1260
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.032620906829834,
      "learning_rate": 2.611559455628032e-05,
      "loss": 0.758,
      "step": 1265
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0539131164550781,
      "learning_rate": 2.596491929749782e-05,
      "loss": 0.7496,
      "step": 1270
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.042515516281128,
      "learning_rate": 2.5814208927370058e-05,
      "loss": 0.7966,
      "step": 1275
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.069256067276001,
      "learning_rate": 2.5663468929924416e-05,
      "loss": 0.7983,
      "step": 1280
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.1166701316833496,
      "learning_rate": 2.5512704790266346e-05,
      "loss": 0.782,
      "step": 1285
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.1310538053512573,
      "learning_rate": 2.5361921994379762e-05,
      "loss": 0.7803,
      "step": 1290
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0530989170074463,
      "learning_rate": 2.5211126028927464e-05,
      "loss": 0.7767,
      "step": 1295
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9479928612709045,
      "learning_rate": 2.5060322381051454e-05,
      "loss": 0.7785,
      "step": 1300
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0809898376464844,
      "learning_rate": 2.490951653817328e-05,
      "loss": 0.7937,
      "step": 1305
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.1864748001098633,
      "learning_rate": 2.4758713987794356e-05,
      "loss": 0.7758,
      "step": 1310
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.0354814529418945,
      "learning_rate": 2.460792021729629e-05,
      "loss": 0.7883,
      "step": 1315
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0926134586334229,
      "learning_rate": 2.4457140713741237e-05,
      "loss": 0.7592,
      "step": 1320
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.1131216287612915,
      "learning_rate": 2.4306380963672173e-05,
      "loss": 0.7743,
      "step": 1325
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9857012033462524,
      "learning_rate": 2.4155646452913296e-05,
      "loss": 0.7546,
      "step": 1330
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0760465860366821,
      "learning_rate": 2.4004942666370414e-05,
      "loss": 0.7599,
      "step": 1335
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.017417311668396,
      "learning_rate": 2.385427508783133e-05,
      "loss": 0.7697,
      "step": 1340
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.9683998823165894,
      "learning_rate": 2.3703649199766312e-05,
      "loss": 0.7301,
      "step": 1345
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1570144891738892,
      "learning_rate": 2.355307048312863e-05,
      "loss": 0.7594,
      "step": 1350
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.010827898979187,
      "learning_rate": 2.340254441715506e-05,
      "loss": 0.7559,
      "step": 1355
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.057120442390442,
      "learning_rate": 2.3252076479166536e-05,
      "loss": 0.7572,
      "step": 1360
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.1107980012893677,
      "learning_rate": 2.310167214436885e-05,
      "loss": 0.7639,
      "step": 1365
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.059336543083191,
      "learning_rate": 2.2951336885653398e-05,
      "loss": 0.7503,
      "step": 1370
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1385219097137451,
      "learning_rate": 2.2801076173398038e-05,
      "loss": 0.7805,
      "step": 1375
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.054930329322815,
      "learning_rate": 2.2650895475268086e-05,
      "loss": 0.7576,
      "step": 1380
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.9713359475135803,
      "learning_rate": 2.250080025601727e-05,
      "loss": 0.7803,
      "step": 1385
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0692071914672852,
      "learning_rate": 2.235079597728893e-05,
      "loss": 0.7599,
      "step": 1390
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.081255316734314,
      "learning_rate": 2.2200888097417307e-05,
      "loss": 0.7691,
      "step": 1395
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.0213249921798706,
      "learning_rate": 2.2051082071228854e-05,
      "loss": 0.7586,
      "step": 1400
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0547064542770386,
      "learning_rate": 2.190138334984381e-05,
      "loss": 0.7709,
      "step": 1405
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1130887269973755,
      "learning_rate": 2.175179738047781e-05,
      "loss": 0.7932,
      "step": 1410
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.0473777055740356,
      "learning_rate": 2.160232960624371e-05,
      "loss": 0.7813,
      "step": 1415
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.157493233680725,
      "learning_rate": 2.1452985465953466e-05,
      "loss": 0.7429,
      "step": 1420
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.0882740020751953,
      "learning_rate": 2.1303770393920284e-05,
      "loss": 0.7741,
      "step": 1425
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0997018814086914,
      "learning_rate": 2.115468981976083e-05,
      "loss": 0.7609,
      "step": 1430
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0016050338745117,
      "learning_rate": 2.1005749168197696e-05,
      "loss": 0.7704,
      "step": 1435
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.004859209060669,
      "learning_rate": 2.0856953858861995e-05,
      "loss": 0.7635,
      "step": 1440
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.9812244772911072,
      "learning_rate": 2.0708309306096132e-05,
      "loss": 0.7701,
      "step": 1445
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.104548692703247,
      "learning_rate": 2.0559820918756825e-05,
      "loss": 0.7676,
      "step": 1450
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.0609599351882935,
      "learning_rate": 2.0411494100018246e-05,
      "loss": 0.7523,
      "step": 1455
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.0991655588150024,
      "learning_rate": 2.0263334247175445e-05,
      "loss": 0.791,
      "step": 1460
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0822575092315674,
      "learning_rate": 2.0115346751447928e-05,
      "loss": 0.7657,
      "step": 1465
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0597450733184814,
      "learning_rate": 1.9967536997783494e-05,
      "loss": 0.75,
      "step": 1470
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1054295301437378,
      "learning_rate": 1.9819910364662324e-05,
      "loss": 0.7568,
      "step": 1475
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1304677724838257,
      "learning_rate": 1.9672472223901198e-05,
      "loss": 0.7813,
      "step": 1480
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0420162677764893,
      "learning_rate": 1.9525227940458067e-05,
      "loss": 0.7553,
      "step": 1485
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0390580892562866,
      "learning_rate": 1.9378182872236837e-05,
      "loss": 0.7367,
      "step": 1490
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.09962797164917,
      "learning_rate": 1.9231342369892412e-05,
      "loss": 0.7682,
      "step": 1495
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.0871256589889526,
      "learning_rate": 1.9084711776635958e-05,
      "loss": 0.7676,
      "step": 1500
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.9868214726448059,
      "learning_rate": 1.89382964280405e-05,
      "loss": 0.7339,
      "step": 1505
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.0338045358657837,
      "learning_rate": 1.8792101651846804e-05,
      "loss": 0.7692,
      "step": 1510
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1616472005844116,
      "learning_rate": 1.8646132767769446e-05,
      "loss": 0.7695,
      "step": 1515
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9674529433250427,
      "learning_rate": 1.850039508730328e-05,
      "loss": 0.7615,
      "step": 1520
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.109579086303711,
      "learning_rate": 1.8354893913530157e-05,
      "loss": 0.7529,
      "step": 1525
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0601122379302979,
      "learning_rate": 1.8209634540925966e-05,
      "loss": 0.7746,
      "step": 1530
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0422176122665405,
      "learning_rate": 1.806462225516794e-05,
      "loss": 0.7551,
      "step": 1535
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.041281819343567,
      "learning_rate": 1.79198623329424e-05,
      "loss": 0.7755,
      "step": 1540
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0899579524993896,
      "learning_rate": 1.777536004175266e-05,
      "loss": 0.7568,
      "step": 1545
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1356303691864014,
      "learning_rate": 1.7631120639727393e-05,
      "loss": 0.7474,
      "step": 1550
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0649323463439941,
      "learning_rate": 1.748714937542933e-05,
      "loss": 0.7622,
      "step": 1555
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.1217025518417358,
      "learning_rate": 1.7343451487664214e-05,
      "loss": 0.7691,
      "step": 1560
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.0098466873168945,
      "learning_rate": 1.72000322052902e-05,
      "loss": 0.7825,
      "step": 1565
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9928804039955139,
      "learning_rate": 1.7056896747027628e-05,
      "loss": 0.8003,
      "step": 1570
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0931396484375,
      "learning_rate": 1.6914050321269047e-05,
      "loss": 0.8113,
      "step": 1575
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0047450065612793,
      "learning_rate": 1.677149812588975e-05,
      "loss": 0.7813,
      "step": 1580
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0500538349151611,
      "learning_rate": 1.6629245348058614e-05,
      "loss": 0.7645,
      "step": 1585
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0119556188583374,
      "learning_rate": 1.648729716404935e-05,
      "loss": 0.7951,
      "step": 1590
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.103309154510498,
      "learning_rate": 1.634565873905215e-05,
      "loss": 0.7654,
      "step": 1595
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1503963470458984,
      "learning_rate": 1.620433522698575e-05,
      "loss": 0.7977,
      "step": 1600
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.0451089143753052,
      "learning_rate": 1.6063331770309886e-05,
      "loss": 0.7209,
      "step": 1605
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.077926754951477,
      "learning_rate": 1.5922653499838137e-05,
      "loss": 0.7609,
      "step": 1610
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.0733120441436768,
      "learning_rate": 1.5782305534551278e-05,
      "loss": 0.7678,
      "step": 1615
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.1539009809494019,
      "learning_rate": 1.5642292981410976e-05,
      "loss": 0.746,
      "step": 1620
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.0373862981796265,
      "learning_rate": 1.5502620935173967e-05,
      "loss": 0.7345,
      "step": 1625
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.1616926193237305,
      "learning_rate": 1.5363294478206666e-05,
      "loss": 0.7751,
      "step": 1630
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.0739384889602661,
      "learning_rate": 1.522431868030026e-05,
      "loss": 0.8049,
      "step": 1635
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.1861834526062012,
      "learning_rate": 1.5085698598486175e-05,
      "loss": 0.7894,
      "step": 1640
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.0518370866775513,
      "learning_rate": 1.4947439276852104e-05,
      "loss": 0.803,
      "step": 1645
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.0953783988952637,
      "learning_rate": 1.4809545746358447e-05,
      "loss": 0.7548,
      "step": 1650
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.0950669050216675,
      "learning_rate": 1.4672023024655256e-05,
      "loss": 0.7839,
      "step": 1655
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.0890721082687378,
      "learning_rate": 1.4534876115899631e-05,
      "loss": 0.791,
      "step": 1660
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.0688774585723877,
      "learning_rate": 1.4398110010573662e-05,
      "loss": 0.7425,
      "step": 1665
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.030354380607605,
      "learning_rate": 1.4261729685302808e-05,
      "loss": 0.7242,
      "step": 1670
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.2356526851654053,
      "learning_rate": 1.4125740102674817e-05,
      "loss": 0.7557,
      "step": 1675
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.024789571762085,
      "learning_rate": 1.399014621105914e-05,
      "loss": 0.7203,
      "step": 1680
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.1641128063201904,
      "learning_rate": 1.3854952944426919e-05,
      "loss": 0.758,
      "step": 1685
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.0363850593566895,
      "learning_rate": 1.3720165222171372e-05,
      "loss": 0.7477,
      "step": 1690
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.016335129737854,
      "learning_rate": 1.358578794892883e-05,
      "loss": 0.7408,
      "step": 1695
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.0217134952545166,
      "learning_rate": 1.3451826014400295e-05,
      "loss": 0.7747,
      "step": 1700
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.183732271194458,
      "learning_rate": 1.331828429317345e-05,
      "loss": 0.7475,
      "step": 1705
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.0606410503387451,
      "learning_rate": 1.3185167644545327e-05,
      "loss": 0.7821,
      "step": 1710
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.0406709909439087,
      "learning_rate": 1.3052480912345482e-05,
      "loss": 0.7843,
      "step": 1715
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.0814050436019897,
      "learning_rate": 1.2920228924759728e-05,
      "loss": 0.7615,
      "step": 1720
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.1374692916870117,
      "learning_rate": 1.2788416494154446e-05,
      "loss": 0.796,
      "step": 1725
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.1126059293746948,
      "learning_rate": 1.265704841690151e-05,
      "loss": 0.7677,
      "step": 1730
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9850059747695923,
      "learning_rate": 1.2526129473203695e-05,
      "loss": 0.7578,
      "step": 1735
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.0747277736663818,
      "learning_rate": 1.239566442692079e-05,
      "loss": 0.7656,
      "step": 1740
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.2411412000656128,
      "learning_rate": 1.226565802539621e-05,
      "loss": 0.7519,
      "step": 1745
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.1276235580444336,
      "learning_rate": 1.2136114999284288e-05,
      "loss": 0.7616,
      "step": 1750
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.1150596141815186,
      "learning_rate": 1.20070400623781e-05,
      "loss": 0.752,
      "step": 1755
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.0753936767578125,
      "learning_rate": 1.187843791143799e-05,
      "loss": 0.7486,
      "step": 1760
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.23600172996521,
      "learning_rate": 1.1750313226020607e-05,
      "loss": 0.7568,
      "step": 1765
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.034753680229187,
      "learning_rate": 1.1622670668308663e-05,
      "loss": 0.7269,
      "step": 1770
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.128592848777771,
      "learning_rate": 1.149551488294127e-05,
      "loss": 0.766,
      "step": 1775
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.0480303764343262,
      "learning_rate": 1.1368850496844941e-05,
      "loss": 0.8024,
      "step": 1780
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.1436558961868286,
      "learning_rate": 1.1242682119065218e-05,
      "loss": 0.7414,
      "step": 1785
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.134548306465149,
      "learning_rate": 1.1117014340598986e-05,
      "loss": 0.7571,
      "step": 1790
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.1433173418045044,
      "learning_rate": 1.0991851734227354e-05,
      "loss": 0.7603,
      "step": 1795
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.0783401727676392,
      "learning_rate": 1.086719885434935e-05,
      "loss": 0.801,
      "step": 1800
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.1169549226760864,
      "learning_rate": 1.0743060236816105e-05,
      "loss": 0.7271,
      "step": 1805
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.0793765783309937,
      "learning_rate": 1.0619440398765864e-05,
      "loss": 0.7826,
      "step": 1810
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.0923429727554321,
      "learning_rate": 1.0496343838459596e-05,
      "loss": 0.7542,
      "step": 1815
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.0061306953430176,
      "learning_rate": 1.0373775035117305e-05,
      "loss": 0.7578,
      "step": 1820
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.1342440843582153,
      "learning_rate": 1.025173844875508e-05,
      "loss": 0.7481,
      "step": 1825
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.094594955444336,
      "learning_rate": 1.013023852002274e-05,
      "loss": 0.7425,
      "step": 1830
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.088600516319275,
      "learning_rate": 1.00092796700423e-05,
      "loss": 0.7439,
      "step": 1835
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.0607900619506836,
      "learning_rate": 9.888866300247077e-06,
      "loss": 0.7526,
      "step": 1840
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.1114959716796875,
      "learning_rate": 9.76900279222153e-06,
      "loss": 0.7135,
      "step": 1845
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.0566192865371704,
      "learning_rate": 9.649693507541818e-06,
      "loss": 0.7808,
      "step": 1850
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.0829423666000366,
      "learning_rate": 9.530942787617137e-06,
      "loss": 0.7611,
      "step": 1855
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.0794637203216553,
      "learning_rate": 9.412754953531663e-06,
      "loss": 0.7083,
      "step": 1860
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.1333848237991333,
      "learning_rate": 9.29513430588739e-06,
      "loss": 0.7443,
      "step": 1865
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.1520402431488037,
      "learning_rate": 9.178085124647603e-06,
      "loss": 0.7931,
      "step": 1870
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.082702398300171,
      "learning_rate": 9.061611668981151e-06,
      "loss": 0.7762,
      "step": 1875
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.167069435119629,
      "learning_rate": 8.945718177107465e-06,
      "loss": 0.7109,
      "step": 1880
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.0105406045913696,
      "learning_rate": 8.830408866142325e-06,
      "loss": 0.7678,
      "step": 1885
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.0026620626449585,
      "learning_rate": 8.715687931944449e-06,
      "loss": 0.7251,
      "step": 1890
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.040805459022522,
      "learning_rate": 8.601559548962756e-06,
      "loss": 0.7522,
      "step": 1895
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.070908546447754,
      "learning_rate": 8.4880278700845e-06,
      "loss": 0.7485,
      "step": 1900
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.1466526985168457,
      "learning_rate": 8.375097026484176e-06,
      "loss": 0.742,
      "step": 1905
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.1677641868591309,
      "learning_rate": 8.262771127473143e-06,
      "loss": 0.7349,
      "step": 1910
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.0727952718734741,
      "learning_rate": 8.151054260350125e-06,
      "loss": 0.7481,
      "step": 1915
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.0894103050231934,
      "learning_rate": 8.039950490252505e-06,
      "loss": 0.7771,
      "step": 1920
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.0974708795547485,
      "learning_rate": 7.929463860008355e-06,
      "loss": 0.753,
      "step": 1925
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.1195508241653442,
      "learning_rate": 7.819598389989358e-06,
      "loss": 0.7436,
      "step": 1930
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.0654561519622803,
      "learning_rate": 7.71035807796451e-06,
      "loss": 0.7381,
      "step": 1935
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.1017465591430664,
      "learning_rate": 7.601746898954645e-06,
      "loss": 0.7304,
      "step": 1940
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.0728358030319214,
      "learning_rate": 7.493768805087786e-06,
      "loss": 0.7513,
      "step": 1945
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.062376618385315,
      "learning_rate": 7.386427725455372e-06,
      "loss": 0.7581,
      "step": 1950
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.161454677581787,
      "learning_rate": 7.279727565969233e-06,
      "loss": 0.7475,
      "step": 1955
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.093670129776001,
      "learning_rate": 7.173672209219495e-06,
      "loss": 0.7678,
      "step": 1960
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.1486454010009766,
      "learning_rate": 7.0682655143332945e-06,
      "loss": 0.7368,
      "step": 1965
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.1253875494003296,
      "learning_rate": 6.963511316834359e-06,
      "loss": 0.7535,
      "step": 1970
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.093714952468872,
      "learning_rate": 6.859413428503428e-06,
      "loss": 0.7678,
      "step": 1975
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.0381590127944946,
      "learning_rate": 6.7559756372395475e-06,
      "loss": 0.7632,
      "step": 1980
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.0089575052261353,
      "learning_rate": 6.653201706922279e-06,
      "loss": 0.7347,
      "step": 1985
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.169196367263794,
      "learning_rate": 6.551095377274671e-06,
      "loss": 0.7503,
      "step": 1990
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.140437126159668,
      "learning_rate": 6.449660363727236e-06,
      "loss": 0.7637,
      "step": 1995
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.1577361822128296,
      "learning_rate": 6.348900357282719e-06,
      "loss": 0.7319,
      "step": 2000
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.1387324333190918,
      "learning_rate": 6.248819024381805e-06,
      "loss": 0.7385,
      "step": 2005
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.111075520515442,
      "learning_rate": 6.149420006769718e-06,
      "loss": 0.7806,
      "step": 2010
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.107416033744812,
      "learning_rate": 6.050706921363672e-06,
      "loss": 0.7442,
      "step": 2015
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.0942529439926147,
      "learning_rate": 5.952683360121297e-06,
      "loss": 0.7769,
      "step": 2020
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.096994161605835,
      "learning_rate": 5.8553528899098984e-06,
      "loss": 0.7509,
      "step": 2025
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.0390585660934448,
      "learning_rate": 5.758719052376693e-06,
      "loss": 0.7526,
      "step": 2030
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.123249888420105,
      "learning_rate": 5.662785363819928e-06,
      "loss": 0.7596,
      "step": 2035
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.084191083908081,
      "learning_rate": 5.567555315060918e-06,
      "loss": 0.7479,
      "step": 2040
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.0477081537246704,
      "learning_rate": 5.47303237131706e-06,
      "loss": 0.7594,
      "step": 2045
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.085468053817749,
      "learning_rate": 5.379219972075691e-06,
      "loss": 0.7592,
      "step": 2050
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.1044015884399414,
      "learning_rate": 5.2861215309689625e-06,
      "loss": 0.7237,
      "step": 2055
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.016601800918579,
      "learning_rate": 5.193740435649622e-06,
      "loss": 0.7549,
      "step": 2060
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.1205264329910278,
      "learning_rate": 5.10208004766774e-06,
      "loss": 0.7706,
      "step": 2065
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.1077412366867065,
      "learning_rate": 5.011143702348387e-06,
      "loss": 0.7375,
      "step": 2070
    },
    {
      "epoch": 2.39,
      "grad_norm": 1.0887237787246704,
      "learning_rate": 4.920934708670288e-06,
      "loss": 0.7557,
      "step": 2075
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.1393030881881714,
      "learning_rate": 4.831456349145386e-06,
      "loss": 0.7685,
      "step": 2080
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.2230207920074463,
      "learning_rate": 4.742711879699413e-06,
      "loss": 0.7313,
      "step": 2085
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.1114474534988403,
      "learning_rate": 4.6547045295534245e-06,
      "loss": 0.7371,
      "step": 2090
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.0735853910446167,
      "learning_rate": 4.567437501106272e-06,
      "loss": 0.7425,
      "step": 2095
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.042967677116394,
      "learning_rate": 4.480913969818098e-06,
      "loss": 0.7387,
      "step": 2100
    },
    {
      "epoch": 2.42,
      "grad_norm": 1.0844058990478516,
      "learning_rate": 4.395137084094763e-06,
      "loss": 0.7774,
      "step": 2105
    },
    {
      "epoch": 2.43,
      "grad_norm": 1.1647388935089111,
      "learning_rate": 4.310109965173317e-06,
      "loss": 0.7574,
      "step": 2110
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.1270784139633179,
      "learning_rate": 4.2258357070083825e-06,
      "loss": 0.759,
      "step": 2115
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.1275197267532349,
      "learning_rate": 4.142317376159599e-06,
      "loss": 0.7556,
      "step": 2120
    },
    {
      "epoch": 2.45,
      "grad_norm": 1.1258113384246826,
      "learning_rate": 4.05955801168004e-06,
      "loss": 0.7506,
      "step": 2125
    },
    {
      "epoch": 2.45,
      "grad_norm": 1.2840064764022827,
      "learning_rate": 3.977560625005608e-06,
      "loss": 0.7521,
      "step": 2130
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.0883560180664062,
      "learning_rate": 3.8963281998454615e-06,
      "loss": 0.7302,
      "step": 2135
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.1265347003936768,
      "learning_rate": 3.815863692073476e-06,
      "loss": 0.7572,
      "step": 2140
    },
    {
      "epoch": 2.47,
      "grad_norm": 1.1500804424285889,
      "learning_rate": 3.736170029620628e-06,
      "loss": 0.7445,
      "step": 2145
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.124381422996521,
      "learning_rate": 3.6572501123685017e-06,
      "loss": 0.7289,
      "step": 2150
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.2632861137390137,
      "learning_rate": 3.579106812043742e-06,
      "loss": 0.7621,
      "step": 2155
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.1351068019866943,
      "learning_rate": 3.5017429721135807e-06,
      "loss": 0.735,
      "step": 2160
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.1228753328323364,
      "learning_rate": 3.42516140768234e-06,
      "loss": 0.7531,
      "step": 2165
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.0940848588943481,
      "learning_rate": 3.3493649053890326e-06,
      "loss": 0.75,
      "step": 2170
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.1337193250656128,
      "learning_rate": 3.27435622330593e-06,
      "loss": 0.7433,
      "step": 2175
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.1568526029586792,
      "learning_rate": 3.2001380908382174e-06,
      "loss": 0.7608,
      "step": 2180
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.1180412769317627,
      "learning_rate": 3.1267132086246683e-06,
      "loss": 0.7734,
      "step": 2185
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.0699505805969238,
      "learning_rate": 3.05408424843939e-06,
      "loss": 0.7862,
      "step": 2190
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.0953073501586914,
      "learning_rate": 2.982253853094588e-06,
      "loss": 0.7726,
      "step": 2195
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.1420719623565674,
      "learning_rate": 2.9112246363443953e-06,
      "loss": 0.7486,
      "step": 2200
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.121119737625122,
      "learning_rate": 2.840999182789797e-06,
      "loss": 0.7278,
      "step": 2205
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.202702522277832,
      "learning_rate": 2.7715800477845334e-06,
      "loss": 0.7558,
      "step": 2210
    },
    {
      "epoch": 2.55,
      "grad_norm": 1.1120219230651855,
      "learning_rate": 2.7029697573421527e-06,
      "loss": 0.7362,
      "step": 2215
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.1873313188552856,
      "learning_rate": 2.635170808044077e-06,
      "loss": 0.7701,
      "step": 2220
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.0970180034637451,
      "learning_rate": 2.5681856669487774e-06,
      "loss": 0.7471,
      "step": 2225
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.096869945526123,
      "learning_rate": 2.5020167715019694e-06,
      "loss": 0.7497,
      "step": 2230
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.1076909303665161,
      "learning_rate": 2.436666529447948e-06,
      "loss": 0.7599,
      "step": 2235
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.0435259342193604,
      "learning_rate": 2.372137318741968e-06,
      "loss": 0.7546,
      "step": 2240
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.1169100999832153,
      "learning_rate": 2.3084314874637135e-06,
      "loss": 0.7438,
      "step": 2245
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.0630370378494263,
      "learning_rate": 2.245551353731845e-06,
      "loss": 0.7479,
      "step": 2250
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.1765047311782837,
      "learning_rate": 2.1834992056196714e-06,
      "loss": 0.7678,
      "step": 2255
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.0780633687973022,
      "learning_rate": 2.122277301071868e-06,
      "loss": 0.7439,
      "step": 2260
    },
    {
      "epoch": 2.61,
      "grad_norm": 1.0822035074234009,
      "learning_rate": 2.061887867822343e-06,
      "loss": 0.7799,
      "step": 2265
    },
    {
      "epoch": 2.61,
      "grad_norm": 1.0520232915878296,
      "learning_rate": 2.0023331033131394e-06,
      "loss": 0.7306,
      "step": 2270
    },
    {
      "epoch": 2.62,
      "grad_norm": 1.060572624206543,
      "learning_rate": 1.9436151746145077e-06,
      "loss": 0.7749,
      "step": 2275
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.0976682901382446,
      "learning_rate": 1.8857362183460264e-06,
      "loss": 0.7959,
      "step": 2280
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.0819216966629028,
      "learning_rate": 1.8286983405988723e-06,
      "loss": 0.7661,
      "step": 2285
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.1862701177597046,
      "learning_rate": 1.7725036168591751e-06,
      "loss": 0.7931,
      "step": 2290
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.0679484605789185,
      "learning_rate": 1.7171540919324936e-06,
      "loss": 0.7449,
      "step": 2295
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.0951207876205444,
      "learning_rate": 1.662651779869423e-06,
      "loss": 0.7662,
      "step": 2300
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.1254150867462158,
      "learning_rate": 1.608998663892286e-06,
      "loss": 0.735,
      "step": 2305
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.0958824157714844,
      "learning_rate": 1.5561966963229924e-06,
      "loss": 0.7705,
      "step": 2310
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.0359389781951904,
      "learning_rate": 1.5042477985119707e-06,
      "loss": 0.7633,
      "step": 2315
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.1759107112884521,
      "learning_rate": 1.4531538607682805e-06,
      "loss": 0.7633,
      "step": 2320
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.1522886753082275,
      "learning_rate": 1.4029167422908107e-06,
      "loss": 0.7573,
      "step": 2325
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.105221152305603,
      "learning_rate": 1.3535382711006432e-06,
      "loss": 0.7446,
      "step": 2330
    },
    {
      "epoch": 2.69,
      "grad_norm": 1.1478158235549927,
      "learning_rate": 1.3050202439745168e-06,
      "loss": 0.7383,
      "step": 2335
    },
    {
      "epoch": 2.69,
      "grad_norm": 1.1389867067337036,
      "learning_rate": 1.2573644263794483e-06,
      "loss": 0.7476,
      "step": 2340
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.2168387174606323,
      "learning_rate": 1.210572552408515e-06,
      "loss": 0.701,
      "step": 2345
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.0519781112670898,
      "learning_rate": 1.1646463247177246e-06,
      "loss": 0.7283,
      "step": 2350
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.245977759361267,
      "learning_rate": 1.1195874144640738e-06,
      "loss": 0.7362,
      "step": 2355
    },
    {
      "epoch": 2.72,
      "grad_norm": 1.1417819261550903,
      "learning_rate": 1.07539746124474e-06,
      "loss": 0.734,
      "step": 2360
    },
    {
      "epoch": 2.72,
      "grad_norm": 1.111659049987793,
      "learning_rate": 1.0320780730374152e-06,
      "loss": 0.7432,
      "step": 2365
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.0987770557403564,
      "learning_rate": 9.896308261417936e-07,
      "loss": 0.7427,
      "step": 2370
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.1296812295913696,
      "learning_rate": 9.480572651222208e-07,
      "loss": 0.7567,
      "step": 2375
    },
    {
      "epoch": 2.74,
      "grad_norm": 1.1186031103134155,
      "learning_rate": 9.073589027514789e-07,
      "loss": 0.7438,
      "step": 2380
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.0730934143066406,
      "learning_rate": 8.675372199557552e-07,
      "loss": 0.7365,
      "step": 2385
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.1592084169387817,
      "learning_rate": 8.285936657607407e-07,
      "loss": 0.7913,
      "step": 2390
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.1099317073822021,
      "learning_rate": 7.905296572389087e-07,
      "loss": 0.7571,
      "step": 2395
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.1839897632598877,
      "learning_rate": 7.533465794579558e-07,
      "loss": 0.7559,
      "step": 2400
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.133105993270874,
      "learning_rate": 7.170457854303897e-07,
      "loss": 0.7207,
      "step": 2405
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.0542383193969727,
      "learning_rate": 6.816285960643071e-07,
      "loss": 0.7452,
      "step": 2410
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.2091131210327148,
      "learning_rate": 6.470963001153269e-07,
      "loss": 0.7688,
      "step": 2415
    },
    {
      "epoch": 2.79,
      "grad_norm": 1.1547797918319702,
      "learning_rate": 6.134501541396831e-07,
      "loss": 0.7696,
      "step": 2420
    },
    {
      "epoch": 2.79,
      "grad_norm": 1.194833517074585,
      "learning_rate": 5.806913824485255e-07,
      "loss": 0.7543,
      "step": 2425
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.1200952529907227,
      "learning_rate": 5.488211770633467e-07,
      "loss": 0.7484,
      "step": 2430
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.1919225454330444,
      "learning_rate": 5.178406976726169e-07,
      "loss": 0.7391,
      "step": 2435
    },
    {
      "epoch": 2.81,
      "grad_norm": 1.0980442762374878,
      "learning_rate": 4.877510715895817e-07,
      "loss": 0.7136,
      "step": 2440
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.2806603908538818,
      "learning_rate": 4.5855339371125294e-07,
      "loss": 0.7842,
      "step": 2445
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.1699713468551636,
      "learning_rate": 4.302487264785521e-07,
      "loss": 0.7411,
      "step": 2450
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.023995280265808,
      "learning_rate": 4.0283809983765186e-07,
      "loss": 0.7644,
      "step": 2455
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.0985348224639893,
      "learning_rate": 3.7632251120252036e-07,
      "loss": 0.7721,
      "step": 2460
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.1487473249435425,
      "learning_rate": 3.5070292541859453e-07,
      "loss": 0.7504,
      "step": 2465
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.1150355339050293,
      "learning_rate": 3.259802747276941e-07,
      "loss": 0.7798,
      "step": 2470
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.0872344970703125,
      "learning_rate": 3.021554587340936e-07,
      "loss": 0.7312,
      "step": 2475
    },
    {
      "epoch": 2.86,
      "grad_norm": 1.0794851779937744,
      "learning_rate": 2.7922934437178695e-07,
      "loss": 0.7518,
      "step": 2480
    },
    {
      "epoch": 2.86,
      "grad_norm": 1.2057915925979614,
      "learning_rate": 2.572027658729409e-07,
      "loss": 0.7517,
      "step": 2485
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.0631966590881348,
      "learning_rate": 2.3607652473754128e-07,
      "loss": 0.745,
      "step": 2490
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.069686770439148,
      "learning_rate": 2.158513897042247e-07,
      "loss": 0.733,
      "step": 2495
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.1419715881347656,
      "learning_rate": 1.9652809672231209e-07,
      "loss": 0.7473,
      "step": 2500
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.1075249910354614,
      "learning_rate": 1.7810734892501624e-07,
      "loss": 0.7912,
      "step": 2505
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.0861929655075073,
      "learning_rate": 1.6058981660387608e-07,
      "loss": 0.7544,
      "step": 2510
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.0440901517868042,
      "learning_rate": 1.4397613718434845e-07,
      "loss": 0.7693,
      "step": 2515
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.0806342363357544,
      "learning_rate": 1.2826691520262114e-07,
      "loss": 0.7382,
      "step": 2520
    },
    {
      "epoch": 2.91,
      "grad_norm": 1.0712848901748657,
      "learning_rate": 1.1346272228361654e-07,
      "loss": 0.7604,
      "step": 2525
    },
    {
      "epoch": 2.91,
      "grad_norm": 1.0989834070205688,
      "learning_rate": 9.956409712018333e-08,
      "loss": 0.7261,
      "step": 2530
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.13245689868927,
      "learning_rate": 8.657154545350654e-08,
      "loss": 0.7483,
      "step": 2535
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.0310429334640503,
      "learning_rate": 7.448554005469455e-08,
      "loss": 0.7485,
      "step": 2540
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.1049522161483765,
      "learning_rate": 6.330652070758448e-08,
      "loss": 0.7616,
      "step": 2545
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.070068359375,
      "learning_rate": 5.3034894192727224e-08,
      "loss": 0.7394,
      "step": 2550
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.146837592124939,
      "learning_rate": 4.367103427260211e-08,
      "loss": 0.7392,
      "step": 2555
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.0770338773727417,
      "learning_rate": 3.521528167800547e-08,
      "loss": 0.7617,
      "step": 2560
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.0574194192886353,
      "learning_rate": 2.7667944095643994e-08,
      "loss": 0.7412,
      "step": 2565
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.1724693775177002,
      "learning_rate": 2.1029296156965804e-08,
      "loss": 0.7568,
      "step": 2570
    },
    {
      "epoch": 2.97,
      "grad_norm": 1.1169402599334717,
      "learning_rate": 1.52995794281352e-08,
      "loss": 0.7313,
      "step": 2575
    },
    {
      "epoch": 2.97,
      "grad_norm": 1.0928009748458862,
      "learning_rate": 1.0479002401264648e-08,
      "loss": 0.7501,
      "step": 2580
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.1591182947158813,
      "learning_rate": 6.5677404868264015e-09,
      "loss": 0.7582,
      "step": 2585
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.0170118808746338,
      "learning_rate": 3.565936007254855e-09,
      "loss": 0.761,
      "step": 2590
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.056962251663208,
      "learning_rate": 1.4736981917812253e-09,
      "loss": 0.7439,
      "step": 2595
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.0866320133209229,
      "learning_rate": 2.911031724561752e-10,
      "loss": 0.7573,
      "step": 2600
    }
  ],
  "logging_steps": 5,
  "max_steps": 2604,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 2.864309635756032e+18,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
