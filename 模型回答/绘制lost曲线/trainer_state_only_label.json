{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.997697620874904,
  "eval_steps": 500,
  "global_step": 1953,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 2.3780174255371094,
      "learning_rate": 4.999919138286634e-05,
      "loss": 1.6791,
      "step": 5
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.00417160987854,
      "learning_rate": 4.9996765583774294e-05,
      "loss": 1.3277,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.857088565826416,
      "learning_rate": 4.999272275964727e-05,
      "loss": 1.2757,
      "step": 15
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.8716306686401367,
      "learning_rate": 4.9987063172013025e-05,
      "loss": 0.8562,
      "step": 20
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4183683395385742,
      "learning_rate": 4.997978718698673e-05,
      "loss": 0.3954,
      "step": 25
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7272524237632751,
      "learning_rate": 4.997089527524725e-05,
      "loss": 0.3349,
      "step": 30
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6776389479637146,
      "learning_rate": 4.9960388012006784e-05,
      "loss": 0.1615,
      "step": 35
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5406501293182373,
      "learning_rate": 4.994826607697358e-05,
      "loss": 0.2681,
      "step": 40
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.32779961824417114,
      "learning_rate": 4.993453025430797e-05,
      "loss": 0.2805,
      "step": 45
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7993959784507751,
      "learning_rate": 4.9919181432571686e-05,
      "loss": 0.2134,
      "step": 50
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4371465742588043,
      "learning_rate": 4.990222060467035e-05,
      "loss": 0.1643,
      "step": 55
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.36025193333625793,
      "learning_rate": 4.988364886778925e-05,
      "loss": 0.1819,
      "step": 60
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0396541357040405,
      "learning_rate": 4.986346742332234e-05,
      "loss": 0.2147,
      "step": 65
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5400023460388184,
      "learning_rate": 4.984167757679458e-05,
      "loss": 0.1326,
      "step": 70
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7982261776924133,
      "learning_rate": 4.981828073777741e-05,
      "loss": 0.1638,
      "step": 75
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7138338685035706,
      "learning_rate": 4.979327841979764e-05,
      "loss": 0.145,
      "step": 80
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.577260434627533,
      "learning_rate": 4.9766672240239485e-05,
      "loss": 0.1351,
      "step": 85
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3234034776687622,
      "learning_rate": 4.9738463920239955e-05,
      "loss": 0.1958,
      "step": 90
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.143918752670288,
      "learning_rate": 4.970865528457751e-05,
      "loss": 0.1396,
      "step": 95
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7631222605705261,
      "learning_rate": 4.967724826155404e-05,
      "loss": 0.1045,
      "step": 100
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6385708451271057,
      "learning_rate": 4.964424488287009e-05,
      "loss": 0.136,
      "step": 105
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.626973032951355,
      "learning_rate": 4.960964728349348e-05,
      "loss": 0.1114,
      "step": 110
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2125591039657593,
      "learning_rate": 4.957345770152113e-05,
      "loss": 0.1448,
      "step": 115
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2566620707511902,
      "learning_rate": 4.9535678478034307e-05,
      "loss": 0.0997,
      "step": 120
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44108182191848755,
      "learning_rate": 4.9496312056947226e-05,
      "loss": 0.1085,
      "step": 125
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5848275423049927,
      "learning_rate": 4.945536098484888e-05,
      "loss": 0.1313,
      "step": 130
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.4693443775177002,
      "learning_rate": 4.941282791083836e-05,
      "loss": 0.0834,
      "step": 135
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.971985936164856,
      "learning_rate": 4.936871558635346e-05,
      "loss": 0.0866,
      "step": 140
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8444632291793823,
      "learning_rate": 4.9323026864992675e-05,
      "loss": 0.071,
      "step": 145
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.47356775403022766,
      "learning_rate": 4.927576470233065e-05,
      "loss": 0.0655,
      "step": 150
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0253866910934448,
      "learning_rate": 4.922693215572695e-05,
      "loss": 0.0612,
      "step": 155
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.45299002528190613,
      "learning_rate": 4.917653238412827e-05,
      "loss": 0.0499,
      "step": 160
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7833584547042847,
      "learning_rate": 4.9124568647864134e-05,
      "loss": 0.0708,
      "step": 165
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6191295385360718,
      "learning_rate": 4.9071044308435927e-05,
      "loss": 0.0578,
      "step": 170
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0307523012161255,
      "learning_rate": 4.901596282829948e-05,
      "loss": 0.0871,
      "step": 175
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.5207585096359253,
      "learning_rate": 4.89593277706411e-05,
      "loss": 0.0425,
      "step": 180
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6382516622543335,
      "learning_rate": 4.8901142799147003e-05,
      "loss": 0.0386,
      "step": 185
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8717602491378784,
      "learning_rate": 4.884141167776639e-05,
      "loss": 0.0455,
      "step": 190
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.3689444363117218,
      "learning_rate": 4.8780138270467915e-05,
      "loss": 0.0491,
      "step": 195
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4116661548614502,
      "learning_rate": 4.871732654098974e-05,
      "loss": 0.0456,
      "step": 200
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.3264620304107666,
      "learning_rate": 4.86529805525831e-05,
      "loss": 0.0339,
      "step": 205
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.487017035484314,
      "learning_rate": 4.858710446774951e-05,
      "loss": 0.0232,
      "step": 210
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8645203113555908,
      "learning_rate": 4.851970254797143e-05,
      "loss": 0.0363,
      "step": 215
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6340810060501099,
      "learning_rate": 4.845077915343664e-05,
      "loss": 0.0229,
      "step": 220
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.30602121353149414,
      "learning_rate": 4.8380338742756157e-05,
      "loss": 0.0219,
      "step": 225
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6304946541786194,
      "learning_rate": 4.830838587267582e-05,
      "loss": 0.0374,
      "step": 230
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.19059111177921295,
      "learning_rate": 4.823492519778151e-05,
      "loss": 0.0224,
      "step": 235
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0816574096679688,
      "learning_rate": 4.8159961470198065e-05,
      "loss": 0.0351,
      "step": 240
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4996147155761719,
      "learning_rate": 4.808349953928184e-05,
      "loss": 0.0143,
      "step": 245
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.19739913940429688,
      "learning_rate": 4.800554435130703e-05,
      "loss": 0.0107,
      "step": 250
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.948381245136261,
      "learning_rate": 4.7926100949145685e-05,
      "loss": 0.0168,
      "step": 255
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9652219414710999,
      "learning_rate": 4.78451744719415e-05,
      "loss": 0.0214,
      "step": 260
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1132337674498558,
      "learning_rate": 4.7762770154777355e-05,
      "loss": 0.0093,
      "step": 265
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7365275621414185,
      "learning_rate": 4.767889332833667e-05,
      "loss": 0.0132,
      "step": 270
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6741588115692139,
      "learning_rate": 4.759354941855857e-05,
      "loss": 0.0182,
      "step": 275
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.10103988647460938,
      "learning_rate": 4.750674394628687e-05,
      "loss": 0.0114,
      "step": 280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4042171835899353,
      "learning_rate": 4.741848252691292e-05,
      "loss": 0.0152,
      "step": 285
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7095809578895569,
      "learning_rate": 4.732877087001243e-05,
      "loss": 0.019,
      "step": 290
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.140584945678711,
      "learning_rate": 4.723761477897601e-05,
      "loss": 0.0232,
      "step": 295
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5723257660865784,
      "learning_rate": 4.714502015063383e-05,
      "loss": 0.0216,
      "step": 300
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.14155395328998566,
      "learning_rate": 4.705099297487412e-05,
      "loss": 0.0301,
      "step": 305
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5542672872543335,
      "learning_rate": 4.6955539334255716e-05,
      "loss": 0.036,
      "step": 310
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.23254860937595367,
      "learning_rate": 4.685866540361456e-05,
      "loss": 0.0143,
      "step": 315
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7153581380844116,
      "learning_rate": 4.676037744966425e-05,
      "loss": 0.0159,
      "step": 320
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2012016326189041,
      "learning_rate": 4.666068183059068e-05,
      "loss": 0.0134,
      "step": 325
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7873539924621582,
      "learning_rate": 4.655958499564072e-05,
      "loss": 0.0225,
      "step": 330
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.544342577457428,
      "learning_rate": 4.645709348470499e-05,
      "loss": 0.0155,
      "step": 335
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8257351517677307,
      "learning_rate": 4.635321392789484e-05,
      "loss": 0.0141,
      "step": 340
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.40578073263168335,
      "learning_rate": 4.6247953045113415e-05,
      "loss": 0.0101,
      "step": 345
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.48684412240982056,
      "learning_rate": 4.6141317645621e-05,
      "loss": 0.0134,
      "step": 350
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6731985211372375,
      "learning_rate": 4.603331462759446e-05,
      "loss": 0.012,
      "step": 355
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0460442304611206,
      "learning_rate": 4.5923950977681084e-05,
      "loss": 0.0223,
      "step": 360
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40272948145866394,
      "learning_rate": 4.581323377054656e-05,
      "loss": 0.0178,
      "step": 365
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.4351106286048889,
      "learning_rate": 4.570117016841732e-05,
      "loss": 0.014,
      "step": 370
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.31738293170928955,
      "learning_rate": 4.558776742061729e-05,
      "loss": 0.0076,
      "step": 375
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.19844461977481842,
      "learning_rate": 4.547303286309885e-05,
      "loss": 0.0091,
      "step": 380
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6796026825904846,
      "learning_rate": 4.535697391796832e-05,
      "loss": 0.0178,
      "step": 385
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.08867599815130234,
      "learning_rate": 4.523959809300582e-05,
      "loss": 0.0085,
      "step": 390
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.1707111597061157,
      "learning_rate": 4.512091298117961e-05,
      "loss": 0.0153,
      "step": 395
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.34649544954299927,
      "learning_rate": 4.500092626015488e-05,
      "loss": 0.0128,
      "step": 400
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7920206189155579,
      "learning_rate": 4.487964569179711e-05,
      "loss": 0.0135,
      "step": 405
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.829697847366333,
      "learning_rate": 4.475707912166994e-05,
      "loss": 0.0181,
      "step": 410
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4192302227020264,
      "learning_rate": 4.463323447852766e-05,
      "loss": 0.0204,
      "step": 415
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.039905309677124,
      "learning_rate": 4.45081197738023e-05,
      "loss": 0.0198,
      "step": 420
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9517975449562073,
      "learning_rate": 4.4381743101085366e-05,
      "loss": 0.0173,
      "step": 425
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5986053347587585,
      "learning_rate": 4.4254112635604294e-05,
      "loss": 0.0157,
      "step": 430
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.13106800615787506,
      "learning_rate": 4.412523663369358e-05,
      "loss": 0.0073,
      "step": 435
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.10717152804136276,
      "learning_rate": 4.399512343226068e-05,
      "loss": 0.0133,
      "step": 440
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5057545304298401,
      "learning_rate": 4.386378144824671e-05,
      "loss": 0.0126,
      "step": 445
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.06503070145845413,
      "learning_rate": 4.373121917808196e-05,
      "loss": 0.0166,
      "step": 450
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.35218021273612976,
      "learning_rate": 4.359744519713628e-05,
      "loss": 0.0201,
      "step": 455
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8907344937324524,
      "learning_rate": 4.346246815916429e-05,
      "loss": 0.0094,
      "step": 460
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7011261582374573,
      "learning_rate": 4.332629679574566e-05,
      "loss": 0.0327,
      "step": 465
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.36303621530532837,
      "learning_rate": 4.318893991572018e-05,
      "loss": 0.0148,
      "step": 470
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5866491794586182,
      "learning_rate": 4.3050406404617976e-05,
      "loss": 0.0333,
      "step": 475
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7656921744346619,
      "learning_rate": 4.291070522408471e-05,
      "loss": 0.0173,
      "step": 480
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7350103855133057,
      "learning_rate": 4.276984541130183e-05,
      "loss": 0.0193,
      "step": 485
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7615335583686829,
      "learning_rate": 4.262783607840199e-05,
      "loss": 0.0206,
      "step": 490
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5047107338905334,
      "learning_rate": 4.2484686411879554e-05,
      "loss": 0.0086,
      "step": 495
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.13696198165416718,
      "learning_rate": 4.234040567199637e-05,
      "loss": 0.0192,
      "step": 500
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.07553595304489136,
      "learning_rate": 4.2195003192182716e-05,
      "loss": 0.0132,
      "step": 505
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.16770711541175842,
      "learning_rate": 4.2048488378433493e-05,
      "loss": 0.023,
      "step": 510
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.20396386086940765,
      "learning_rate": 4.1900870708699804e-05,
      "loss": 0.0128,
      "step": 515
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.18653179705142975,
      "learning_rate": 4.17521597322758e-05,
      "loss": 0.0056,
      "step": 520
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3027969598770142,
      "learning_rate": 4.160236506918098e-05,
      "loss": 0.0166,
      "step": 525
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2670309543609619,
      "learning_rate": 4.145149640953782e-05,
      "loss": 0.0046,
      "step": 530
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4316096901893616,
      "learning_rate": 4.1299563512944964e-05,
      "loss": 0.0059,
      "step": 535
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2528788447380066,
      "learning_rate": 4.114657620784589e-05,
      "loss": 0.0036,
      "step": 540
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5763236284255981,
      "learning_rate": 4.099254439089309e-05,
      "loss": 0.0155,
      "step": 545
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4069998562335968,
      "learning_rate": 4.0837478026307864e-05,
      "loss": 0.0077,
      "step": 550
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.20374196767807007,
      "learning_rate": 4.068138714523575e-05,
      "loss": 0.0039,
      "step": 555
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.10123475641012192,
      "learning_rate": 4.052428184509762e-05,
      "loss": 0.0054,
      "step": 560
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0460205078125,
      "learning_rate": 4.0366172288936474e-05,
      "loss": 0.0096,
      "step": 565
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8846014738082886,
      "learning_rate": 4.020706870476e-05,
      "loss": 0.0108,
      "step": 570
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.023150617256760597,
      "learning_rate": 4.0046981384878936e-05,
      "loss": 0.0097,
      "step": 575
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8021381497383118,
      "learning_rate": 3.988592068524125e-05,
      "loss": 0.0106,
      "step": 580
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6562977433204651,
      "learning_rate": 3.9723897024762255e-05,
      "loss": 0.006,
      "step": 585
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.25697052478790283,
      "learning_rate": 3.956092088465058e-05,
      "loss": 0.0089,
      "step": 590
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.05026373639702797,
      "learning_rate": 3.9397002807730166e-05,
      "loss": 0.0046,
      "step": 595
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.657948911190033,
      "learning_rate": 3.923215339775826e-05,
      "loss": 0.0094,
      "step": 600
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.325285792350769,
      "learning_rate": 3.906638331873945e-05,
      "loss": 0.0121,
      "step": 605
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.13126060366630554,
      "learning_rate": 3.8899703294235825e-05,
      "loss": 0.0043,
      "step": 610
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6117089986801147,
      "learning_rate": 3.8732124106673277e-05,
      "loss": 0.0055,
      "step": 615
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.28623390197753906,
      "learning_rate": 3.856365659664399e-05,
      "loss": 0.0121,
      "step": 620
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.029845530167222023,
      "learning_rate": 3.839431166220517e-05,
      "loss": 0.0033,
      "step": 625
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4334576725959778,
      "learning_rate": 3.822410025817406e-05,
      "loss": 0.0072,
      "step": 630
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5720790028572083,
      "learning_rate": 3.805303339541927e-05,
      "loss": 0.0056,
      "step": 635
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.33903953433036804,
      "learning_rate": 3.7881122140148505e-05,
      "loss": 0.0045,
      "step": 640
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1260935068130493,
      "learning_rate": 3.770837761319267e-05,
      "loss": 0.0077,
      "step": 645
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.12527479231357574,
      "learning_rate": 3.7534810989286506e-05,
      "loss": 0.0139,
      "step": 650
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5927979946136475,
      "learning_rate": 3.73604334963457e-05,
      "loss": 0.0029,
      "step": 655
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.04483413323760033,
      "learning_rate": 3.718525641474052e-05,
      "loss": 0.004,
      "step": 660
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.720382571220398,
      "learning_rate": 3.700929107656614e-05,
      "loss": 0.0052,
      "step": 665
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.3165152668952942,
      "learning_rate": 3.6832548864909545e-05,
      "loss": 0.0072,
      "step": 670
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6333890557289124,
      "learning_rate": 3.6655041213113184e-05,
      "loss": 0.0031,
      "step": 675
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.635682225227356,
      "learning_rate": 3.647677960403536e-05,
      "loss": 0.0038,
      "step": 680
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.14961594343185425,
      "learning_rate": 3.629777556930736e-05,
      "loss": 0.0095,
      "step": 685
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.046376314014196396,
      "learning_rate": 3.611804068858756e-05,
      "loss": 0.0174,
      "step": 690
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.04164329543709755,
      "learning_rate": 3.5937586588812264e-05,
      "loss": 0.0125,
      "step": 695
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.8066554069519043,
      "learning_rate": 3.575642494344365e-05,
      "loss": 0.0077,
      "step": 700
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.15713047981262207,
      "learning_rate": 3.5574567471714545e-05,
      "loss": 0.0061,
      "step": 705
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.09482955932617188,
      "learning_rate": 3.539202593787033e-05,
      "loss": 0.0016,
      "step": 710
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5287539958953857,
      "learning_rate": 3.520881215040798e-05,
      "loss": 0.0032,
      "step": 715
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1341659426689148,
      "learning_rate": 3.50249379613121e-05,
      "loss": 0.0026,
      "step": 720
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.21517696976661682,
      "learning_rate": 3.484041526528826e-05,
      "loss": 0.0061,
      "step": 725
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.3316810727119446,
      "learning_rate": 3.4655255998993555e-05,
      "loss": 0.005,
      "step": 730
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6032671332359314,
      "learning_rate": 3.44694721402644e-05,
      "loss": 0.0115,
      "step": 735
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.1554064750671387,
      "learning_rate": 3.42830757073417e-05,
      "loss": 0.0071,
      "step": 740
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.7451140880584717,
      "learning_rate": 3.409607875809339e-05,
      "loss": 0.0103,
      "step": 745
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.2624266743659973,
      "learning_rate": 3.390849338923446e-05,
      "loss": 0.0175,
      "step": 750
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5518974661827087,
      "learning_rate": 3.3720331735544344e-05,
      "loss": 0.0066,
      "step": 755
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5053962469100952,
      "learning_rate": 3.353160596908202e-05,
      "loss": 0.0024,
      "step": 760
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.39088520407676697,
      "learning_rate": 3.3342328298398565e-05,
      "loss": 0.0087,
      "step": 765
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.07134664058685303,
      "learning_rate": 3.315251096774737e-05,
      "loss": 0.006,
      "step": 770
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9497495889663696,
      "learning_rate": 3.2962166256292113e-05,
      "loss": 0.0159,
      "step": 775
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.4462248086929321,
      "learning_rate": 3.277130647731238e-05,
      "loss": 0.0088,
      "step": 780
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.11147211492061615,
      "learning_rate": 3.257994397740717e-05,
      "loss": 0.0064,
      "step": 785
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8437920808792114,
      "learning_rate": 3.238809113569617e-05,
      "loss": 0.0158,
      "step": 790
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.40474727749824524,
      "learning_rate": 3.219576036301898e-05,
      "loss": 0.003,
      "step": 795
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.5480023622512817,
      "learning_rate": 3.200296410113225e-05,
      "loss": 0.0061,
      "step": 800
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.06213662028312683,
      "learning_rate": 3.1809714821904834e-05,
      "loss": 0.0055,
      "step": 805
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5262470245361328,
      "learning_rate": 3.161602502651099e-05,
      "loss": 0.0022,
      "step": 810
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9096381664276123,
      "learning_rate": 3.1421907244621696e-05,
      "loss": 0.0098,
      "step": 815
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5691858530044556,
      "learning_rate": 3.122737403359409e-05,
      "loss": 0.0047,
      "step": 820
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.23374736309051514,
      "learning_rate": 3.1032437977659196e-05,
      "loss": 0.0093,
      "step": 825
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.21078087389469147,
      "learning_rate": 3.083711168710778e-05,
      "loss": 0.0051,
      "step": 830
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.30116480588912964,
      "learning_rate": 3.0641407797474656e-05,
      "loss": 0.0036,
      "step": 835
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.29032018780708313,
      "learning_rate": 3.0445338968721287e-05,
      "loss": 0.0041,
      "step": 840
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.16308122873306274,
      "learning_rate": 3.024891788441684e-05,
      "loss": 0.0039,
      "step": 845
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9263933897018433,
      "learning_rate": 3.0052157250917613e-05,
      "loss": 0.0046,
      "step": 850
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.015907390043139458,
      "learning_rate": 2.9855069796545186e-05,
      "loss": 0.0014,
      "step": 855
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.08582461625337601,
      "learning_rate": 2.9657668270762957e-05,
      "loss": 0.0023,
      "step": 860
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.0775216594338417,
      "learning_rate": 2.945996544335139e-05,
      "loss": 0.0115,
      "step": 865
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.029138371348381042,
      "learning_rate": 2.926197410358199e-05,
      "loss": 0.0071,
      "step": 870
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.8795763850212097,
      "learning_rate": 2.906370705938991e-05,
      "loss": 0.0146,
      "step": 875
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.06209937855601311,
      "learning_rate": 2.8865177136545485e-05,
      "loss": 0.0073,
      "step": 880
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.9356656074523926,
      "learning_rate": 2.8666397177824473e-05,
      "loss": 0.006,
      "step": 885
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.4389558732509613,
      "learning_rate": 2.846738004217732e-05,
      "loss": 0.0105,
      "step": 890
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.115585207939148,
      "learning_rate": 2.826813860389729e-05,
      "loss": 0.0116,
      "step": 895
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.09754233062267303,
      "learning_rate": 2.8068685751787636e-05,
      "loss": 0.0041,
      "step": 900
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.08623792231082916,
      "learning_rate": 2.786903438832785e-05,
      "loss": 0.0069,
      "step": 905
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.3404742479324341,
      "learning_rate": 2.7669197428838972e-05,
      "loss": 0.0079,
      "step": 910
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.014261710457503796,
      "learning_rate": 2.746918780064818e-05,
      "loss": 0.0009,
      "step": 915
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4846956729888916,
      "learning_rate": 2.726901844225243e-05,
      "loss": 0.0145,
      "step": 920
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.07221342623233795,
      "learning_rate": 2.706870230248157e-05,
      "loss": 0.0066,
      "step": 925
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.30410540103912354,
      "learning_rate": 2.686825233966061e-05,
      "loss": 0.0036,
      "step": 930
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9814242124557495,
      "learning_rate": 2.66676815207715e-05,
      "loss": 0.0111,
      "step": 935
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.05890956521034241,
      "learning_rate": 2.6467002820614296e-05,
      "loss": 0.0025,
      "step": 940
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.4278927743434906,
      "learning_rate": 2.6266229220967818e-05,
      "loss": 0.0056,
      "step": 945
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.08160845190286636,
      "learning_rate": 2.606537370974989e-05,
      "loss": 0.0015,
      "step": 950
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7943028807640076,
      "learning_rate": 2.5864449280177116e-05,
      "loss": 0.005,
      "step": 955
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.719741940498352,
      "learning_rate": 2.5663468929924416e-05,
      "loss": 0.0071,
      "step": 960
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.05798197165131569,
      "learning_rate": 2.5462445660284173e-05,
      "loss": 0.0015,
      "step": 965
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.48209694027900696,
      "learning_rate": 2.526139247532518e-05,
      "loss": 0.0075,
      "step": 970
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.07827986776828766,
      "learning_rate": 2.5060322381051454e-05,
      "loss": 0.0082,
      "step": 975
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.913392961025238,
      "learning_rate": 2.485924838456086e-05,
      "loss": 0.0096,
      "step": 980
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.06729981303215027,
      "learning_rate": 2.4658183493203688e-05,
      "loss": 0.0015,
      "step": 985
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.7269454002380371,
      "learning_rate": 2.4457140713741237e-05,
      "loss": 0.0108,
      "step": 990
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.0728239044547081,
      "learning_rate": 2.425613305150439e-05,
      "loss": 0.0063,
      "step": 995
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.20075853168964386,
      "learning_rate": 2.405517350955232e-05,
      "loss": 0.005,
      "step": 1000
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.059312351047992706,
      "learning_rate": 2.385427508783133e-05,
      "loss": 0.0014,
      "step": 1005
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6831297278404236,
      "learning_rate": 2.365345078233389e-05,
      "loss": 0.0078,
      "step": 1010
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.11678735911846161,
      "learning_rate": 2.3452713584257955e-05,
      "loss": 0.0042,
      "step": 1015
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5783286094665527,
      "learning_rate": 2.3252076479166536e-05,
      "loss": 0.0038,
      "step": 1020
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.07964431494474411,
      "learning_rate": 2.30515524461477e-05,
      "loss": 0.0015,
      "step": 1025
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0202618837356567,
      "learning_rate": 2.285115445697495e-05,
      "loss": 0.017,
      "step": 1030
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5858151912689209,
      "learning_rate": 2.2650895475268086e-05,
      "loss": 0.0098,
      "step": 1035
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5082405209541321,
      "learning_rate": 2.2450788455654627e-05,
      "loss": 0.0096,
      "step": 1040
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.35917848348617554,
      "learning_rate": 2.2250846342931734e-05,
      "loss": 0.0066,
      "step": 1045
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.06899569183588028,
      "learning_rate": 2.2051082071228854e-05,
      "loss": 0.0088,
      "step": 1050
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21353964507579803,
      "learning_rate": 2.1851508563171008e-05,
      "loss": 0.0041,
      "step": 1055
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.12374360859394073,
      "learning_rate": 2.1652138729042846e-05,
      "loss": 0.0035,
      "step": 1060
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.050859078764915466,
      "learning_rate": 2.1452985465953466e-05,
      "loss": 0.0014,
      "step": 1065
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.11677180230617523,
      "learning_rate": 2.125406165700214e-05,
      "loss": 0.0015,
      "step": 1070
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.041838388890028,
      "learning_rate": 2.105538017044487e-05,
      "loss": 0.0035,
      "step": 1075
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2740808129310608,
      "learning_rate": 2.0856953858861995e-05,
      "loss": 0.002,
      "step": 1080
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23195263743400574,
      "learning_rate": 2.0658795558326743e-05,
      "loss": 0.004,
      "step": 1085
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.021595478057861328,
      "learning_rate": 2.0460918087574877e-05,
      "loss": 0.0064,
      "step": 1090
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.026353390887379646,
      "learning_rate": 2.0263334247175445e-05,
      "loss": 0.0021,
      "step": 1095
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6135066151618958,
      "learning_rate": 2.006605681870275e-05,
      "loss": 0.0022,
      "step": 1100
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.04303145036101341,
      "learning_rate": 1.9869098563909475e-05,
      "loss": 0.0111,
      "step": 1105
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.047876328229904175,
      "learning_rate": 1.9672472223901198e-05,
      "loss": 0.008,
      "step": 1110
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.011408967897295952,
      "learning_rate": 1.9476190518312103e-05,
      "loss": 0.0042,
      "step": 1115
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.38980618119239807,
      "learning_rate": 1.928026614448221e-05,
      "loss": 0.0055,
      "step": 1120
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.3056769371032715,
      "learning_rate": 1.9084711776635958e-05,
      "loss": 0.008,
      "step": 1125
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.13378289341926575,
      "learning_rate": 1.8889540065062338e-05,
      "loss": 0.0009,
      "step": 1130
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.1316368579864502,
      "learning_rate": 1.869476363529656e-05,
      "loss": 0.0041,
      "step": 1135
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.04361475631594658,
      "learning_rate": 1.850039508730328e-05,
      "loss": 0.0065,
      "step": 1140
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.2098582983016968,
      "learning_rate": 1.8306446994661558e-05,
      "loss": 0.0116,
      "step": 1145
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.038923680782318115,
      "learning_rate": 1.811293190375144e-05,
      "loss": 0.0031,
      "step": 1150
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.351346492767334,
      "learning_rate": 1.79198623329424e-05,
      "loss": 0.0122,
      "step": 1155
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.8027710318565369,
      "learning_rate": 1.772725077178346e-05,
      "loss": 0.0152,
      "step": 1160
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.13410575687885284,
      "learning_rate": 1.7535109680195296e-05,
      "loss": 0.0057,
      "step": 1165
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5328288078308105,
      "learning_rate": 1.7343451487664214e-05,
      "loss": 0.0024,
      "step": 1170
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.12238345295190811,
      "learning_rate": 1.715228859243807e-05,
      "loss": 0.0061,
      "step": 1175
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.03558316454291344,
      "learning_rate": 1.6961633360724262e-05,
      "loss": 0.0047,
      "step": 1180
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.22656463086605072,
      "learning_rate": 1.677149812588975e-05,
      "loss": 0.0044,
      "step": 1185
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.41537994146347046,
      "learning_rate": 1.658189518766322e-05,
      "loss": 0.0028,
      "step": 1190
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.629173755645752,
      "learning_rate": 1.6392836811339425e-05,
      "loss": 0.0048,
      "step": 1195
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1685367822647095,
      "learning_rate": 1.620433522698575e-05,
      "loss": 0.0079,
      "step": 1200
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.32047194242477417,
      "learning_rate": 1.6016402628651072e-05,
      "loss": 0.0093,
      "step": 1205
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.03643761947751045,
      "learning_rate": 1.5829051173576905e-05,
      "loss": 0.0053,
      "step": 1210
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.20564503967761993,
      "learning_rate": 1.5642292981410976e-05,
      "loss": 0.0061,
      "step": 1215
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.09640250355005264,
      "learning_rate": 1.545614013342321e-05,
      "loss": 0.0055,
      "step": 1220
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7706432342529297,
      "learning_rate": 1.5270604671724188e-05,
      "loss": 0.0073,
      "step": 1225
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1294594258069992,
      "learning_rate": 1.5085698598486175e-05,
      "loss": 0.0055,
      "step": 1230
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.18506909906864166,
      "learning_rate": 1.4901433875166687e-05,
      "loss": 0.0038,
      "step": 1235
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.04690776765346527,
      "learning_rate": 1.4717822421734718e-05,
      "loss": 0.0016,
      "step": 1240
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.08300373703241348,
      "learning_rate": 1.4534876115899631e-05,
      "loss": 0.0091,
      "step": 1245
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0725252702832222,
      "learning_rate": 1.4352606792342829e-05,
      "loss": 0.0017,
      "step": 1250
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6803539395332336,
      "learning_rate": 1.4171026241952163e-05,
      "loss": 0.0027,
      "step": 1255
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.27458059787750244,
      "learning_rate": 1.399014621105914e-05,
      "loss": 0.0022,
      "step": 1260
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.9330583810806274,
      "learning_rate": 1.3809978400679157e-05,
      "loss": 0.0087,
      "step": 1265
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.01114567555487156,
      "learning_rate": 1.3630534465754463e-05,
      "loss": 0.0016,
      "step": 1270
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.12994267046451569,
      "learning_rate": 1.3451826014400295e-05,
      "loss": 0.0037,
      "step": 1275
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.656537652015686,
      "learning_rate": 1.3273864607153916e-05,
      "loss": 0.0047,
      "step": 1280
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.928547739982605,
      "learning_rate": 1.3096661756226749e-05,
      "loss": 0.0118,
      "step": 1285
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5337716937065125,
      "learning_rate": 1.2920228924759728e-05,
      "loss": 0.006,
      "step": 1290
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.009146059863269329,
      "learning_rate": 1.2744577526081666e-05,
      "loss": 0.0019,
      "step": 1295
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9657672047615051,
      "learning_rate": 1.2569718922971018e-05,
      "loss": 0.0097,
      "step": 1300
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2657276690006256,
      "learning_rate": 1.239566442692079e-05,
      "loss": 0.0064,
      "step": 1305
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.16778664290905,
      "learning_rate": 1.2222425297406783e-05,
      "loss": 0.0024,
      "step": 1310
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.10768909007310867,
      "learning_rate": 1.2050012741159258e-05,
      "loss": 0.0017,
      "step": 1315
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.9255051612854004,
      "learning_rate": 1.187843791143799e-05,
      "loss": 0.0053,
      "step": 1320
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.4298812448978424,
      "learning_rate": 1.1707711907310739e-05,
      "loss": 0.0072,
      "step": 1325
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.631582498550415,
      "learning_rate": 1.1537845772935279e-05,
      "loss": 0.0047,
      "step": 1330
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.02076329104602337,
      "learning_rate": 1.1368850496844941e-05,
      "loss": 0.0043,
      "step": 1335
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5571576356887817,
      "learning_rate": 1.1200737011237763e-05,
      "loss": 0.0111,
      "step": 1340
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.4094970226287842,
      "learning_rate": 1.1033516191269371e-05,
      "loss": 0.0027,
      "step": 1345
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.22830970585346222,
      "learning_rate": 1.086719885434935e-05,
      "loss": 0.0026,
      "step": 1350
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5531481504440308,
      "learning_rate": 1.0701795759441576e-05,
      "loss": 0.0019,
      "step": 1355
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.04366251453757286,
      "learning_rate": 1.0537317606368164e-05,
      "loss": 0.001,
      "step": 1360
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6754520535469055,
      "learning_rate": 1.0373775035117305e-05,
      "loss": 0.0104,
      "step": 1365
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.3105776011943817,
      "learning_rate": 1.0211178625155057e-05,
      "loss": 0.0033,
      "step": 1370
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.06568725407123566,
      "learning_rate": 1.004953889474083e-05,
      "loss": 0.002,
      "step": 1375
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.36405375599861145,
      "learning_rate": 9.888866300247077e-06,
      "loss": 0.0018,
      "step": 1380
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.0543321371078491,
      "learning_rate": 9.729171235482815e-06,
      "loss": 0.0033,
      "step": 1385
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.28276923298835754,
      "learning_rate": 9.570464031021273e-06,
      "loss": 0.0043,
      "step": 1390
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.33468520641326904,
      "learning_rate": 9.412754953531663e-06,
      "loss": 0.0015,
      "step": 1395
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.3292688727378845,
      "learning_rate": 9.256054205114939e-06,
      "loss": 0.0048,
      "step": 1400
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.11407516151666641,
      "learning_rate": 9.100371922643913e-06,
      "loss": 0.0064,
      "step": 1405
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5489856600761414,
      "learning_rate": 8.945718177107465e-06,
      "loss": 0.0102,
      "step": 1410
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.523736298084259,
      "learning_rate": 8.792102972959049e-06,
      "loss": 0.0066,
      "step": 1415
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.26507359743118286,
      "learning_rate": 8.639536247469582e-06,
      "loss": 0.008,
      "step": 1420
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.24737413227558136,
      "learning_rate": 8.4880278700845e-06,
      "loss": 0.0033,
      "step": 1425
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.2121090441942215,
      "learning_rate": 8.33758764178541e-06,
      "loss": 0.0035,
      "step": 1430
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.10555202513933182,
      "learning_rate": 8.188225294455992e-06,
      "loss": 0.0035,
      "step": 1435
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.059041935950517654,
      "learning_rate": 8.039950490252505e-06,
      "loss": 0.0026,
      "step": 1440
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.14541374146938324,
      "learning_rate": 7.89277282097873e-06,
      "loss": 0.0032,
      "step": 1445
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.06119116023182869,
      "learning_rate": 7.74670180746546e-06,
      "loss": 0.0033,
      "step": 1450
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6367602944374084,
      "learning_rate": 7.601746898954645e-06,
      "loss": 0.008,
      "step": 1455
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.26076871156692505,
      "learning_rate": 7.4579174724880875e-06,
      "loss": 0.0032,
      "step": 1460
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.07051920890808105,
      "learning_rate": 7.315222832300875e-06,
      "loss": 0.0051,
      "step": 1465
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.6170724630355835,
      "learning_rate": 7.173672209219495e-06,
      "loss": 0.0081,
      "step": 1470
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6509139537811279,
      "learning_rate": 7.0332747600646566e-06,
      "loss": 0.0026,
      "step": 1475
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.39896637201309204,
      "learning_rate": 6.894039567059007e-06,
      "loss": 0.0064,
      "step": 1480
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.21736429631710052,
      "learning_rate": 6.7559756372395475e-06,
      "loss": 0.0022,
      "step": 1485
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.020282475277781487,
      "learning_rate": 6.6190919018750215e-06,
      "loss": 0.004,
      "step": 1490
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.43397045135498047,
      "learning_rate": 6.483397215888135e-06,
      "loss": 0.0046,
      "step": 1495
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.005842124577611685,
      "learning_rate": 6.348900357282719e-06,
      "loss": 0.0011,
      "step": 1500
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.7606862187385559,
      "learning_rate": 6.215610026575916e-06,
      "loss": 0.0055,
      "step": 1505
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.43757134675979614,
      "learning_rate": 6.083534846235342e-06,
      "loss": 0.0043,
      "step": 1510
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.25916314125061035,
      "learning_rate": 5.952683360121297e-06,
      "loss": 0.0094,
      "step": 1515
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.030188243836164474,
      "learning_rate": 5.8230640329340835e-06,
      "loss": 0.0115,
      "step": 1520
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.18942461907863617,
      "learning_rate": 5.694685249666396e-06,
      "loss": 0.0027,
      "step": 1525
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.2758055627346039,
      "learning_rate": 5.567555315060918e-06,
      "loss": 0.0022,
      "step": 1530
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.2978844940662384,
      "learning_rate": 5.4416824530731495e-06,
      "loss": 0.0048,
      "step": 1535
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.06262149661779404,
      "learning_rate": 5.317074806339295e-06,
      "loss": 0.0018,
      "step": 1540
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6135669350624084,
      "learning_rate": 5.193740435649622e-06,
      "loss": 0.0033,
      "step": 1545
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.18166783452033997,
      "learning_rate": 5.071687319426946e-06,
      "loss": 0.0021,
      "step": 1550
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.12947240471839905,
      "learning_rate": 4.950923353210532e-06,
      "loss": 0.0057,
      "step": 1555
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5017175078392029,
      "learning_rate": 4.831456349145386e-06,
      "loss": 0.006,
      "step": 1560
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.1538306176662445,
      "learning_rate": 4.713294035476798e-06,
      "loss": 0.0062,
      "step": 1565
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.10322088748216629,
      "learning_rate": 4.596444056050492e-06,
      "loss": 0.0058,
      "step": 1570
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.01873895525932312,
      "learning_rate": 4.480913969818098e-06,
      "loss": 0.0015,
      "step": 1575
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.24714934825897217,
      "learning_rate": 4.366711250348176e-06,
      "loss": 0.0043,
      "step": 1580
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.0991453006863594,
      "learning_rate": 4.253843285342807e-06,
      "loss": 0.0083,
      "step": 1585
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.0649803951382637,
      "learning_rate": 4.142317376159599e-06,
      "loss": 0.0021,
      "step": 1590
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.012995541095733643,
      "learning_rate": 4.032140737339443e-06,
      "loss": 0.0013,
      "step": 1595
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6383023262023926,
      "learning_rate": 3.92332049613976e-06,
      "loss": 0.0032,
      "step": 1600
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.18126323819160461,
      "learning_rate": 3.815863692073476e-06,
      "loss": 0.0039,
      "step": 1605
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.41004475951194763,
      "learning_rate": 3.70977727645363e-06,
      "loss": 0.0043,
      "step": 1610
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.18592147529125214,
      "learning_rate": 3.605068111943674e-06,
      "loss": 0.0027,
      "step": 1615
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.03751688823103905,
      "learning_rate": 3.5017429721135807e-06,
      "loss": 0.002,
      "step": 1620
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.10616195201873779,
      "learning_rate": 3.399808541001609e-06,
      "loss": 0.0029,
      "step": 1625
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.8816298842430115,
      "learning_rate": 3.2992714126819644e-06,
      "loss": 0.0034,
      "step": 1630
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.16291025280952454,
      "learning_rate": 3.2001380908382174e-06,
      "loss": 0.0027,
      "step": 1635
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.08916736394166946,
      "learning_rate": 3.1024149883425586e-06,
      "loss": 0.0016,
      "step": 1640
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.16800940036773682,
      "learning_rate": 3.0061084268410006e-06,
      "loss": 0.0019,
      "step": 1645
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.009131602011620998,
      "learning_rate": 2.9112246363443953e-06,
      "loss": 0.0025,
      "step": 1650
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.0386185422539711,
      "learning_rate": 2.817769754825439e-06,
      "loss": 0.0049,
      "step": 1655
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.09169281274080276,
      "learning_rate": 2.7257498278216135e-06,
      "loss": 0.001,
      "step": 1660
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.06907786428928375,
      "learning_rate": 2.635170808044077e-06,
      "loss": 0.0021,
      "step": 1665
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7609915137290955,
      "learning_rate": 2.5460385549926275e-06,
      "loss": 0.0037,
      "step": 1670
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.4588763117790222,
      "learning_rate": 2.45835883457661e-06,
      "loss": 0.0083,
      "step": 1675
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.4431178569793701,
      "learning_rate": 2.372137318741968e-06,
      "loss": 0.0029,
      "step": 1680
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.06827162951231003,
      "learning_rate": 2.2873795851043073e-06,
      "loss": 0.0045,
      "step": 1685
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.1445176601409912,
      "learning_rate": 2.2040911165880723e-06,
      "loss": 0.0021,
      "step": 1690
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.44296741485595703,
      "learning_rate": 2.122277301071868e-06,
      "loss": 0.0026,
      "step": 1695
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.048584915697574615,
      "learning_rate": 2.041943431039953e-06,
      "loss": 0.0009,
      "step": 1700
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6471928954124451,
      "learning_rate": 1.9630947032398067e-06,
      "loss": 0.0025,
      "step": 1705
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.43856000900268555,
      "learning_rate": 1.8857362183460264e-06,
      "loss": 0.0059,
      "step": 1710
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.19957520067691803,
      "learning_rate": 1.8098729806303116e-06,
      "loss": 0.0164,
      "step": 1715
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6979456543922424,
      "learning_rate": 1.7355098976377575e-06,
      "loss": 0.0041,
      "step": 1720
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.07945646345615387,
      "learning_rate": 1.662651779869423e-06,
      "loss": 0.0042,
      "step": 1725
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.555785059928894,
      "learning_rate": 1.591303340471084e-06,
      "loss": 0.0096,
      "step": 1730
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.128324493765831,
      "learning_rate": 1.521469194928396e-06,
      "loss": 0.0029,
      "step": 1735
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.17379818856716156,
      "learning_rate": 1.4531538607682805e-06,
      "loss": 0.0018,
      "step": 1740
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.05698767304420471,
      "learning_rate": 1.3863617572667076e-06,
      "loss": 0.003,
      "step": 1745
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.8050445914268494,
      "learning_rate": 1.3210972051628328e-06,
      "loss": 0.0045,
      "step": 1750
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.0979897752404213,
      "learning_rate": 1.2573644263794483e-06,
      "loss": 0.0027,
      "step": 1755
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.39366087317466736,
      "learning_rate": 1.1951675437499144e-06,
      "loss": 0.0028,
      "step": 1760
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.06446979939937592,
      "learning_rate": 1.1345105807514272e-06,
      "loss": 0.0036,
      "step": 1765
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.2644379734992981,
      "learning_rate": 1.07539746124474e-06,
      "loss": 0.0041,
      "step": 1770
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.9806307554244995,
      "learning_rate": 1.017832009220368e-06,
      "loss": 0.0091,
      "step": 1775
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.22142386436462402,
      "learning_rate": 9.618179485511691e-07,
      "loss": 0.0017,
      "step": 1780
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.4810875952243805,
      "learning_rate": 9.073589027514789e-07,
      "loss": 0.0053,
      "step": 1785
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.03649133816361427,
      "learning_rate": 8.544583947426993e-07,
      "loss": 0.001,
      "step": 1790
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.09048700332641602,
      "learning_rate": 8.031198466253998e-07,
      "loss": 0.0011,
      "step": 1795
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.29046162962913513,
      "learning_rate": 7.533465794579558e-07,
      "loss": 0.004,
      "step": 1800
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.11036808788776398,
      "learning_rate": 7.051418130416932e-07,
      "loss": 0.0028,
      "step": 1805
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.02598191797733307,
      "learning_rate": 6.585086657126177e-07,
      "loss": 0.0044,
      "step": 1810
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.5011013746261597,
      "learning_rate": 6.134501541396831e-07,
      "loss": 0.0024,
      "step": 1815
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.014219610020518303,
      "learning_rate": 5.699691931296463e-07,
      "loss": 0.005,
      "step": 1820
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.1882154941558838,
      "learning_rate": 5.280685954385134e-07,
      "loss": 0.0091,
      "step": 1825
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.008170085959136486,
      "learning_rate": 4.877510715895817e-07,
      "loss": 0.0021,
      "step": 1830
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.46028658747673035,
      "learning_rate": 4.490192296980972e-07,
      "loss": 0.0072,
      "step": 1835
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.013455499894917011,
      "learning_rate": 4.1187557530253105e-07,
      "loss": 0.0018,
      "step": 1840
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.30144166946411133,
      "learning_rate": 3.7632251120252036e-07,
      "loss": 0.0019,
      "step": 1845
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.013897400349378586,
      "learning_rate": 3.423623373034035e-07,
      "loss": 0.0019,
      "step": 1850
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.41807490587234497,
      "learning_rate": 3.0999725046745866e-07,
      "loss": 0.003,
      "step": 1855
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5229052305221558,
      "learning_rate": 2.7922934437178695e-07,
      "loss": 0.0036,
      "step": 1860
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.341053307056427,
      "learning_rate": 2.500606093728708e-07,
      "loss": 0.0065,
      "step": 1865
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6952707767486572,
      "learning_rate": 2.2249293237781854e-07,
      "loss": 0.0061,
      "step": 1870
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5119163990020752,
      "learning_rate": 1.9652809672231209e-07,
      "loss": 0.0115,
      "step": 1875
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.08208479732275009,
      "learning_rate": 1.721677820552242e-07,
      "loss": 0.002,
      "step": 1880
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.47427091002464294,
      "learning_rate": 1.494135642299832e-07,
      "loss": 0.0012,
      "step": 1885
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.1480894684791565,
      "learning_rate": 1.2826691520262114e-07,
      "loss": 0.004,
      "step": 1890
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.7469872236251831,
      "learning_rate": 1.0872920293655553e-07,
      "loss": 0.0033,
      "step": 1895
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.2746882140636444,
      "learning_rate": 9.08016913140991e-08,
      "loss": 0.0018,
      "step": 1900
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6475635766983032,
      "learning_rate": 7.448554005469455e-08,
      "loss": 0.0054,
      "step": 1905
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.10793519765138626,
      "learning_rate": 5.978180463989958e-08,
      "loss": 0.007,
      "step": 1910
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.36781710386276245,
      "learning_rate": 4.669143624510541e-08,
      "loss": 0.0044,
      "step": 1915
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6472190618515015,
      "learning_rate": 3.521528167800547e-08,
      "loss": 0.0091,
      "step": 1920
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.4481835663318634,
      "learning_rate": 2.535408332381417e-08,
      "loss": 0.0026,
      "step": 1925
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6777141690254211,
      "learning_rate": 1.7108479097252548e-08,
      "loss": 0.0053,
      "step": 1930
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.5448853969573975,
      "learning_rate": 1.0479002401264648e-08,
      "loss": 0.005,
      "step": 1935
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.35389798879623413,
      "learning_rate": 5.466082092531188e-09,
      "loss": 0.0044,
      "step": 1940
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.4314138889312744,
      "learning_rate": 2.0700424537056785e-09,
      "loss": 0.0039,
      "step": 1945
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.07375185191631317,
      "learning_rate": 2.911031724561752e-10,
      "loss": 0.0049,
      "step": 1950
    }
  ],
  "logging_steps": 5,
  "max_steps": 1953,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 2.4540058635689656e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
